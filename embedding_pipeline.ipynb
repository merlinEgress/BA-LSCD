{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088d70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "path = '/Users/merlin/Desktop/BA/Bachelorabeit Uni Leipzig/programming/dhox/data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac0ad653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>docSubType</th>\n",
       "      <th>docType</th>\n",
       "      <th>doi</th>\n",
       "      <th>fullText</th>\n",
       "      <th>id</th>\n",
       "      <th>identifier</th>\n",
       "      <th>isPartOf</th>\n",
       "      <th>issueNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>tdmCategory</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>volumeNumber</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>unigramCount</th>\n",
       "      <th>bigramCount</th>\n",
       "      <th>trigramCount</th>\n",
       "      <th>sourceCategory</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[E. Tendayi Achiume, Thomas Spijkerboer, Thoma...</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>introduction</td>\n",
       "      <td>article</td>\n",
       "      <td>10.1017/aju.2020.68</td>\n",
       "      <td>[INTRODUCTION TO THE SYMPOSIUM ON COVID-19, GL...</td>\n",
       "      <td>ark://27927/phzj2xdqwbj</td>\n",
       "      <td>[{'name': 'local_publisher_id', 'value': 'S239...</td>\n",
       "      <td>AJIL Unbound</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>[Social sciences - Human geography, Philosophy...</td>\n",
       "      <td>Introduction to the Symposium on COVID-19, Glo...</td>\n",
       "      <td>http://doi.org/10.1017/aju.2020.68</td>\n",
       "      <td>114</td>\n",
       "      <td>3106</td>\n",
       "      <td>{'challenge': 4, 'Up:': 1, 'racialized': 2, 'w...</td>\n",
       "      <td>{'Europe: Which': 1, 'Supreme Court': 2, 'soft...</td>\n",
       "      <td>{'1-2 (2017). Their': 1, 'two key regional': 1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Lisa B. Haddad, Peggy Goedken, Martina L. Bad...</td>\n",
       "      <td>2012-06-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>article</td>\n",
       "      <td>10.1155/2012/107878</td>\n",
       "      <td>[Hindawi Publishing Corporation\\nInfectious Di...</td>\n",
       "      <td>ark://27927/pgg22m661ng</td>\n",
       "      <td>[{'name': 'doi', 'value': '10.1155/2012/107878...</td>\n",
       "      <td>Infectious Diseases in Obstetrics and Gynecology</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>[Social sciences - Behavioral sciences]</td>\n",
       "      <td>Reproductive Healthcare Needs and Desires in a...</td>\n",
       "      <td>http://doi.org/10.1155/2012/107878</td>\n",
       "      <td>2012</td>\n",
       "      <td>4172</td>\n",
       "      <td>{'exception': 1, 'from': 2, 'Prevention,': 1, ...</td>\n",
       "      <td>{'whether they': 1, '≤45 years': 1, 'Inclusion...</td>\n",
       "      <td>{'hormonal contraceptive use': 2, 'Gynecology ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Kelsey N. Rolofson]</td>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>article</td>\n",
       "      <td>10.17161/urjh.v4i1.13445</td>\n",
       "      <td>[55\\nCapitalist and Communal Foundations in Th...</td>\n",
       "      <td>ark://27927/phzpv6dk0vv</td>\n",
       "      <td>[{'name': 'doi', 'value': '10.17161/urjh.v4i1....</td>\n",
       "      <td>Undergraduate Research Journal in the Humanities</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[Arts - Literature, Social sciences - Behavior...</td>\n",
       "      <td>Capitalist and Communal Foundations in The Bin...</td>\n",
       "      <td>http://doi.org/10.17161/urjh.v4i1.13445</td>\n",
       "      <td>4</td>\n",
       "      <td>4034</td>\n",
       "      <td>{'Dice:': 1, 'influence': 1, 'confused”': 1, '...</td>\n",
       "      <td>{'certain ‘Indian’': 1, 'conflict, which': 1, ...</td>\n",
       "      <td>{'dreams of love': 1, 'to evoke a': 1, '(Bingo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[A. Vetra, L. Vilka, L. Stašová]</td>\n",
       "      <td>2016-09-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>article</td>\n",
       "      <td>10.1051/shsconf/20163000037</td>\n",
       "      <td>[SHS Web of Conferences 30, 00037 (2016) DOI: ...</td>\n",
       "      <td>ark://27927/phxhw908wc</td>\n",
       "      <td>[{'name': 'doi', 'value': '10.1051/shsconf/201...</td>\n",
       "      <td>SHS Web of conferences</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>[Law - Computer law, Social sciences - Communi...</td>\n",
       "      <td>New media face to face – parental monitoring a...</td>\n",
       "      <td>http://doi.org/10.1051/shsconf/20163000037</td>\n",
       "      <td>30</td>\n",
       "      <td>2784</td>\n",
       "      <td>{'H.': 1, 'presence': 1, 'Valkenburg,': 1, 'di...</td>\n",
       "      <td>{'exact time': 2, 'my dad,': 1, 'countries inc...</td>\n",
       "      <td>{'watching, sharing, talking': 1, 'Snider, K. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Andrew Arsan]</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Article</td>\n",
       "      <td>article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\\n\\n\\n\\nmamMashriq &amp;amp; Mahjar: Journal of M...</td>\n",
       "      <td>ark://27927/pjb27jn6pkd</td>\n",
       "      <td>[{'name': 'local_publisher_id', 'value': 'S216...</td>\n",
       "      <td>Mashriq &amp; Mahjar: Journal of Middle East and N...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[Social sciences - Human geography]</td>\n",
       "      <td>Editorial Foreword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>{'for': 1, '\\nEditorial': 1, 'of': 1, '\\n': 2,...</td>\n",
       "      <td>{'Mahjar: Journal': 1, 'African Migration': 1,...</td>\n",
       "      <td>{'Journal of Middle': 1, 'Diaspora StudiesS216...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16907</th>\n",
       "      <td>[F. B. Tarbell]</td>\n",
       "      <td>1910-10-01</td>\n",
       "      <td>research-article</td>\n",
       "      <td>article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[SrcjaeorogicaI ]nltitute of [merica ARCHITE...</td>\n",
       "      <td>http://www.jstor.org/stable/497146</td>\n",
       "      <td>[{'name': 'local_doi', 'value': '10.2307/49714...</td>\n",
       "      <td>American Journal of Archaeology</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[Social sciences - Archaeology, Arts - Art his...</td>\n",
       "      <td>Architecture on Attic Vases</td>\n",
       "      <td>http://www.jstor.org/stable/497146</td>\n",
       "      <td>14</td>\n",
       "      <td>2131</td>\n",
       "      <td>{'4.': 1, 'Theseum,': 1, 'quasi-': 1, 'has': 2...</td>\n",
       "      <td>{'most part': 1, 'so later.': 1, 'TARBELL inte...</td>\n",
       "      <td>{'Still these hints': 1, 'the integrity of': 1...</td>\n",
       "      <td>[Archaeology, Architecture &amp; Architectural His...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16908</th>\n",
       "      <td>[Susan Rathbun-Grubb]</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>research-article</td>\n",
       "      <td>article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[The Lived Experience of Work and Career among...</td>\n",
       "      <td>http://www.jstor.org/stable/48645196</td>\n",
       "      <td>[{'name': 'local_doi', 'value': '10.2307/48645...</td>\n",
       "      <td>The International Journal of Information, Dive...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[Social sciences - Behavioral sciences]</td>\n",
       "      <td>The Lived Experience of Work and Career among ...</td>\n",
       "      <td>http://www.jstor.org/stable/48645196</td>\n",
       "      <td>3</td>\n",
       "      <td>12204</td>\n",
       "      <td>{'confront.': 1, 'demoralizing,': 1, 'meaningf...</td>\n",
       "      <td>{'2015). By': 1, '(2017) 17-country': 1, 'disc...</td>\n",
       "      <td>{'shut up and': 1, 'posts from caregivers': 1,...</td>\n",
       "      <td>[Social Sciences, Library Science]</td>\n",
       "      <td>Individuals with invisible chronic illnesses a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16909</th>\n",
       "      <td>[ARTHUR P. BRIGGS]</td>\n",
       "      <td>1914-11-19</td>\n",
       "      <td>research-article</td>\n",
       "      <td>article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[PARENT-TEACHERS ASSOCIATIONS ARTHUR P. BRIGGS...</td>\n",
       "      <td>http://www.jstor.org/stable/42769705</td>\n",
       "      <td>[{'name': 'local_doi', 'value': '10.2307/42769...</td>\n",
       "      <td>The Journal of Education</td>\n",
       "      <td>18 (2004)</td>\n",
       "      <td>...</td>\n",
       "      <td>[Education - Formal education, Education - Spe...</td>\n",
       "      <td>PARENT-TEACHERS ASSOCIATIONS</td>\n",
       "      <td>http://www.jstor.org/stable/42769705</td>\n",
       "      <td>80</td>\n",
       "      <td>1034</td>\n",
       "      <td>{'fellowship': 1, 'solid': 1, 'eight': 1, 'opp...</td>\n",
       "      <td>{'is an': 1, 'they. VI.': 1, 'an admirable': 1...</td>\n",
       "      <td>{'the benefit. -': 1, 'the least expenditure.'...</td>\n",
       "      <td>[Education, Social Sciences]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16910</th>\n",
       "      <td>[John Duncan, Antoinette Hollister, Clara Mitc...</td>\n",
       "      <td>1901-04-01</td>\n",
       "      <td>research-article</td>\n",
       "      <td>article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[A SPRING STUDY See Mr. Duncan's article on \"A...</td>\n",
       "      <td>http://www.jstor.org/stable/992013</td>\n",
       "      <td>[{'name': 'local_doi', 'value': '10.2307/99201...</td>\n",
       "      <td>The Course of Study</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>[Social sciences - Communications, Arts - Appl...</td>\n",
       "      <td>Art</td>\n",
       "      <td>http://www.jstor.org/stable/992013</td>\n",
       "      <td>1</td>\n",
       "      <td>898</td>\n",
       "      <td>{'exchange;': 1, 'flower': 1, 'dent,': 1, 'bus...</td>\n",
       "      <td>{'telephone exchange;': 1, 'POTTERY 697': 1, '...</td>\n",
       "      <td>{'for beautiful patterns': 1, 'and colors of':...</td>\n",
       "      <td>[Education, Social Sciences]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16911</th>\n",
       "      <td>[Van Meter Ames]</td>\n",
       "      <td>1926-10-28</td>\n",
       "      <td>research-article</td>\n",
       "      <td>article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[THE FUNCTION OF ESTHETIC EXPERIENCE. T HIE es...</td>\n",
       "      <td>http://www.jstor.org/stable/2014728</td>\n",
       "      <td>[{'name': 'local_doi', 'value': '10.2307/20147...</td>\n",
       "      <td>The Journal of Philosophy</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>[Philosophy - Metaphilosophy, Social sciences ...</td>\n",
       "      <td>The Function of Esthetic Experience</td>\n",
       "      <td>http://www.jstor.org/stable/2014728</td>\n",
       "      <td>23</td>\n",
       "      <td>2901</td>\n",
       "      <td>{'\"Poets': 1, 'projected': 1, 'artistic,': 1, ...</td>\n",
       "      <td>{'Esthetic values': 1, 'to solely': 2, 'respon...</td>\n",
       "      <td>{'the animal organism.': 1, 'to tell the': 1, ...</td>\n",
       "      <td>[Humanities, Philosophy]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16912 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 creator datePublished  \\\n",
       "0      [E. Tendayi Achiume, Thomas Spijkerboer, Thoma...    2020-11-09   \n",
       "1      [Lisa B. Haddad, Peggy Goedken, Martina L. Bad...    2012-06-13   \n",
       "2                                   [Kelsey N. Rolofson]    2020-06-29   \n",
       "3                       [A. Vetra, L. Vilka, L. Stašová]    2016-09-14   \n",
       "4                                         [Andrew Arsan]    2015-01-01   \n",
       "...                                                  ...           ...   \n",
       "16907                                    [F. B. Tarbell]    1910-10-01   \n",
       "16908                              [Susan Rathbun-Grubb]    2019-10-01   \n",
       "16909                                 [ARTHUR P. BRIGGS]    1914-11-19   \n",
       "16910  [John Duncan, Antoinette Hollister, Clara Mitc...    1901-04-01   \n",
       "16911                                   [Van Meter Ames]    1926-10-28   \n",
       "\n",
       "             docSubType  docType                          doi  \\\n",
       "0          introduction  article          10.1017/aju.2020.68   \n",
       "1                   NaN  article          10.1155/2012/107878   \n",
       "2                   NaN  article     10.17161/urjh.v4i1.13445   \n",
       "3                   NaN  article  10.1051/shsconf/20163000037   \n",
       "4               Article  article                          NaN   \n",
       "...                 ...      ...                          ...   \n",
       "16907  research-article  article                          NaN   \n",
       "16908  research-article  article                          NaN   \n",
       "16909  research-article  article                          NaN   \n",
       "16910  research-article  article                          NaN   \n",
       "16911  research-article  article                          NaN   \n",
       "\n",
       "                                                fullText  \\\n",
       "0      [INTRODUCTION TO THE SYMPOSIUM ON COVID-19, GL...   \n",
       "1      [Hindawi Publishing Corporation\\nInfectious Di...   \n",
       "2      [55\\nCapitalist and Communal Foundations in Th...   \n",
       "3      [SHS Web of Conferences 30, 00037 (2016) DOI: ...   \n",
       "4      [\\n\\n\\n\\nmamMashriq &amp; Mahjar: Journal of M...   \n",
       "...                                                  ...   \n",
       "16907  [SrcjaeorogicaI ]nltitute of [merica ARCHITE...   \n",
       "16908  [The Lived Experience of Work and Career among...   \n",
       "16909  [PARENT-TEACHERS ASSOCIATIONS ARTHUR P. BRIGGS...   \n",
       "16910  [A SPRING STUDY See Mr. Duncan's article on \"A...   \n",
       "16911  [THE FUNCTION OF ESTHETIC EXPERIENCE. T HIE es...   \n",
       "\n",
       "                                         id  \\\n",
       "0                   ark://27927/phzj2xdqwbj   \n",
       "1                   ark://27927/pgg22m661ng   \n",
       "2                   ark://27927/phzpv6dk0vv   \n",
       "3                    ark://27927/phxhw908wc   \n",
       "4                   ark://27927/pjb27jn6pkd   \n",
       "...                                     ...   \n",
       "16907    http://www.jstor.org/stable/497146   \n",
       "16908  http://www.jstor.org/stable/48645196   \n",
       "16909  http://www.jstor.org/stable/42769705   \n",
       "16910    http://www.jstor.org/stable/992013   \n",
       "16911   http://www.jstor.org/stable/2014728   \n",
       "\n",
       "                                              identifier  \\\n",
       "0      [{'name': 'local_publisher_id', 'value': 'S239...   \n",
       "1      [{'name': 'doi', 'value': '10.1155/2012/107878...   \n",
       "2      [{'name': 'doi', 'value': '10.17161/urjh.v4i1....   \n",
       "3      [{'name': 'doi', 'value': '10.1051/shsconf/201...   \n",
       "4      [{'name': 'local_publisher_id', 'value': 'S216...   \n",
       "...                                                  ...   \n",
       "16907  [{'name': 'local_doi', 'value': '10.2307/49714...   \n",
       "16908  [{'name': 'local_doi', 'value': '10.2307/48645...   \n",
       "16909  [{'name': 'local_doi', 'value': '10.2307/42769...   \n",
       "16910  [{'name': 'local_doi', 'value': '10.2307/99201...   \n",
       "16911  [{'name': 'local_doi', 'value': '10.2307/20147...   \n",
       "\n",
       "                                                isPartOf issueNumber  ...  \\\n",
       "0                                           AJIL Unbound        null  ...   \n",
       "1       Infectious Diseases in Obstetrics and Gynecology        null  ...   \n",
       "2       Undergraduate Research Journal in the Humanities           1  ...   \n",
       "3                                 SHS Web of conferences        null  ...   \n",
       "4      Mashriq & Mahjar: Journal of Middle East and N...           1  ...   \n",
       "...                                                  ...         ...  ...   \n",
       "16907                    American Journal of Archaeology           4  ...   \n",
       "16908  The International Journal of Information, Dive...           4  ...   \n",
       "16909                           The Journal of Education   18 (2004)  ...   \n",
       "16910                                The Course of Study           8  ...   \n",
       "16911                          The Journal of Philosophy          22  ...   \n",
       "\n",
       "                                             tdmCategory  \\\n",
       "0      [Social sciences - Human geography, Philosophy...   \n",
       "1                [Social sciences - Behavioral sciences]   \n",
       "2      [Arts - Literature, Social sciences - Behavior...   \n",
       "3      [Law - Computer law, Social sciences - Communi...   \n",
       "4                    [Social sciences - Human geography]   \n",
       "...                                                  ...   \n",
       "16907  [Social sciences - Archaeology, Arts - Art his...   \n",
       "16908            [Social sciences - Behavioral sciences]   \n",
       "16909  [Education - Formal education, Education - Spe...   \n",
       "16910  [Social sciences - Communications, Arts - Appl...   \n",
       "16911  [Philosophy - Metaphilosophy, Social sciences ...   \n",
       "\n",
       "                                                   title  \\\n",
       "0      Introduction to the Symposium on COVID-19, Glo...   \n",
       "1      Reproductive Healthcare Needs and Desires in a...   \n",
       "2      Capitalist and Communal Foundations in The Bin...   \n",
       "3      New media face to face – parental monitoring a...   \n",
       "4                                     Editorial Foreword   \n",
       "...                                                  ...   \n",
       "16907                        Architecture on Attic Vases   \n",
       "16908  The Lived Experience of Work and Career among ...   \n",
       "16909                       PARENT-TEACHERS ASSOCIATIONS   \n",
       "16910                                                Art   \n",
       "16911                The Function of Esthetic Experience   \n",
       "\n",
       "                                              url  volumeNumber wordCount  \\\n",
       "0              http://doi.org/10.1017/aju.2020.68           114      3106   \n",
       "1              http://doi.org/10.1155/2012/107878          2012      4172   \n",
       "2         http://doi.org/10.17161/urjh.v4i1.13445             4      4034   \n",
       "3      http://doi.org/10.1051/shsconf/20163000037            30      2784   \n",
       "4                                             NaN             3        23   \n",
       "...                                           ...           ...       ...   \n",
       "16907          http://www.jstor.org/stable/497146            14      2131   \n",
       "16908        http://www.jstor.org/stable/48645196             3     12204   \n",
       "16909        http://www.jstor.org/stable/42769705            80      1034   \n",
       "16910          http://www.jstor.org/stable/992013             1       898   \n",
       "16911         http://www.jstor.org/stable/2014728            23      2901   \n",
       "\n",
       "                                            unigramCount  \\\n",
       "0      {'challenge': 4, 'Up:': 1, 'racialized': 2, 'w...   \n",
       "1      {'exception': 1, 'from': 2, 'Prevention,': 1, ...   \n",
       "2      {'Dice:': 1, 'influence': 1, 'confused”': 1, '...   \n",
       "3      {'H.': 1, 'presence': 1, 'Valkenburg,': 1, 'di...   \n",
       "4      {'for': 1, '\\nEditorial': 1, 'of': 1, '\\n': 2,...   \n",
       "...                                                  ...   \n",
       "16907  {'4.': 1, 'Theseum,': 1, 'quasi-': 1, 'has': 2...   \n",
       "16908  {'confront.': 1, 'demoralizing,': 1, 'meaningf...   \n",
       "16909  {'fellowship': 1, 'solid': 1, 'eight': 1, 'opp...   \n",
       "16910  {'exchange;': 1, 'flower': 1, 'dent,': 1, 'bus...   \n",
       "16911  {'\"Poets': 1, 'projected': 1, 'artistic,': 1, ...   \n",
       "\n",
       "                                             bigramCount  \\\n",
       "0      {'Europe: Which': 1, 'Supreme Court': 2, 'soft...   \n",
       "1      {'whether they': 1, '≤45 years': 1, 'Inclusion...   \n",
       "2      {'certain ‘Indian’': 1, 'conflict, which': 1, ...   \n",
       "3      {'exact time': 2, 'my dad,': 1, 'countries inc...   \n",
       "4      {'Mahjar: Journal': 1, 'African Migration': 1,...   \n",
       "...                                                  ...   \n",
       "16907  {'most part': 1, 'so later.': 1, 'TARBELL inte...   \n",
       "16908  {'2015). By': 1, '(2017) 17-country': 1, 'disc...   \n",
       "16909  {'is an': 1, 'they. VI.': 1, 'an admirable': 1...   \n",
       "16910  {'telephone exchange;': 1, 'POTTERY 697': 1, '...   \n",
       "16911  {'Esthetic values': 1, 'to solely': 2, 'respon...   \n",
       "\n",
       "                                            trigramCount  \\\n",
       "0      {'1-2 (2017). Their': 1, 'two key regional': 1...   \n",
       "1      {'hormonal contraceptive use': 2, 'Gynecology ...   \n",
       "2      {'dreams of love': 1, 'to evoke a': 1, '(Bingo...   \n",
       "3      {'watching, sharing, talking': 1, 'Snider, K. ...   \n",
       "4      {'Journal of Middle': 1, 'Diaspora StudiesS216...   \n",
       "...                                                  ...   \n",
       "16907  {'Still these hints': 1, 'the integrity of': 1...   \n",
       "16908  {'shut up and': 1, 'posts from caregivers': 1,...   \n",
       "16909  {'the benefit. -': 1, 'the least expenditure.'...   \n",
       "16910  {'for beautiful patterns': 1, 'and colors of':...   \n",
       "16911  {'the animal organism.': 1, 'to tell the': 1, ...   \n",
       "\n",
       "                                          sourceCategory  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "16907  [Archaeology, Architecture & Architectural His...   \n",
       "16908                 [Social Sciences, Library Science]   \n",
       "16909                       [Education, Social Sciences]   \n",
       "16910                       [Education, Social Sciences]   \n",
       "16911                           [Humanities, Philosophy]   \n",
       "\n",
       "                                                abstract  \n",
       "0                                                    NaN  \n",
       "1                                                    NaN  \n",
       "2                                                    NaN  \n",
       "3                                                    NaN  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "16907                                                NaN  \n",
       "16908  Individuals with invisible chronic illnesses a...  \n",
       "16909                                                NaN  \n",
       "16910                                                NaN  \n",
       "16911                                                NaN  \n",
       "\n",
       "[16912 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pfad: Path: /Users/merlin/Desktop/BA/Bachelorabeit Uni Leipzig/data/1880_nopsy.jsonl\n",
    "# Pfad JSTOR Download mit Textdaten\n",
    "path_social_science = '/Users/merlin/Desktop/BA/Bachelorabeit Uni Leipzig/programming/dhox/data/1880_nopsy.jsonl'\n",
    "\n",
    "\n",
    "# Reader JSONL: In JSONL enthält jede Zeile eine JSON-Datei\n",
    "# Pfad: Path: /Users/merlin/BA/mata_and_text.jsonl\n",
    "data_fullText = pd.read_json(path_social_science, lines=True)\n",
    "display(data_fullText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc640349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#erstes fulltext element aus dem df\n",
    "len(data_fullText['fullText'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c116128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anwenden des modells auf das erste fullText element\n",
    "from transformers import BertModel, BertTokenizer, AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f228f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erste Modelle für testing\n",
    "\n",
    "#model = BertModel.from_pretrained(\"bert-base-uncased\")#\n",
    "#model = SentenceTransformer('intfloat/e5-base')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a858fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bi-encoder for sentences E5 base model + tokenizer from HuggingFace vor geschlagen von gpt\n",
    "#model_name = \"intfloat/e5-base\"\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#model = AutoModel.from_pretrained(model_name)\n",
    "#model.eval()  # disable dropout etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13f43bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loade distilBert a smaller version of bert für kürzere Laufzeit\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31df280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizer je nach Model\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec8e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for splitting input text into chunks of 512 tokens\n",
    "\n",
    "def chunk_text(text, max_len=512):\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    chunks = [tokens[i:i+max_len-2] for i in range(0, len(tokens), max_len-2)]\n",
    "    return [tokenizer.build_inputs_with_special_tokens(chunk) for chunk in chunks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287565da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for splitting input text into chunks of 512 tokens bi-transformer model\n",
    "\n",
    "def chunk_text_bi(text, max_len=512):\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    alphanumeric_tokens = [\n",
    "        token for token in tokens \n",
    "        if tokenizer.decode([token]).strip().isalnum()\n",
    "    ]\n",
    "    chunks = [alphanumeric_tokens[i:i+max_len-2] for i in range(0, len(alphanumeric_tokens), max_len-2)]\n",
    "    return [tokenizer.decode(chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method embTokenDf_bi: Takes a list of text chunks, tokenizes them, and returns a DataFrame with token embeddings\n",
    "def embTokenDf_bi(chunks):\n",
    "    df_outputs = pd.DataFrame()\n",
    "    i = 0\n",
    "    for chunk in chunks:\n",
    "        # Tokenize input chunk\n",
    "        encoded = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        input_ids = encoded[\"input_ids\"]\n",
    "        attention_mask = encoded[\"attention_mask\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Shape: [1, seq_len, hidden_size]\n",
    "        embeddings = output.last_hidden_state.squeeze(0)  # -> [seq_len, hidden_size]\n",
    "\n",
    "        # Get tokens for each ID\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze(0))\n",
    "\n",
    "        # Build dataframe\n",
    "        df_chunk = pd.DataFrame(embeddings.detach().numpy())\n",
    "        df_chunk.insert(0, \"token\", tokens)\n",
    "\n",
    "        df_outputs = pd.concat([df_outputs, df_chunk], ignore_index=True)\n",
    "        i+= 1\n",
    "    print(f\"✔ Processed chunks: {i} \")\n",
    "\n",
    "    return df_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0e38de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methode embTokenDF for distilBert: Takes a list of text chunks, tokenizes them, and returns a DataFrame with token embeddings\n",
    "def embTokenDf_distil(chunks):\n",
    "    df_outputs = pd.DataFrame()\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # Tokenize the input\n",
    "        encoded = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded)\n",
    "\n",
    "        # Last hidden states: [batch_size, seq_len, hidden_dim]\n",
    "        embeddings = output.last_hidden_state.squeeze(0)  # shape: [seq_len, 768]\n",
    "        tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"].squeeze(0))\n",
    "\n",
    "        # Store in DataFrame\n",
    "        df_chunk = pd.DataFrame(embeddings.cpu().numpy())\n",
    "        df_chunk.insert(0, \"token\", tokens)\n",
    "\n",
    "        df_outputs = pd.concat([df_outputs, df_chunk], ignore_index=True)\n",
    "        print(f\"✔ Processed {len(tokens)} tokens\")\n",
    "\n",
    "    return df_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c1d5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bekanntes problem dass die fulltext spalte meherere einzele strings erhält statt einen ganzen\n",
    "def join_strings(list):\n",
    "    text = ''\n",
    "    for _ in list:\n",
    "        text += _\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6542451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embTokenDf(chunks):\n",
    "    df_outputs = pd.DataFrame()\n",
    "    for chunk in chunks:\n",
    "        inputs_ids = torch.tensor([chunk])\n",
    "        attention_mask = torch.ones_like(inputs_ids)\n",
    "        inputs = {\"input_ids\": inputs_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(**inputs)\n",
    "\n",
    "        embeddings = output.last_hidden_state.squeeze(0)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(chunk)\n",
    "\n",
    "        df_chunk = pd.DataFrame(embeddings.detach().numpy())\n",
    "        df_chunk.insert(0, \"token\", tokens)\n",
    "        df_outputs = pd.concat([df_outputs, df_chunk], ignore_index=True)\n",
    "        print(f\"Processed embeddings{len(embeddings)}\")\n",
    "        print(f\"Processed tokens:{len(tokens)}\")\n",
    "    return df_outputs\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0447d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average token embeddings\n",
    "def average_token_embeddings(df):\n",
    "    embedding_cols = df.columns[1:]  # assuming first col is 'token'\n",
    "    df_avg = df.groupby(\"token\")[embedding_cols].mean().reset_index()\n",
    "    return df_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f341add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for similar tokens in two DataFrames\n",
    "def check_similars(text1, text2):\n",
    "    similars = []\n",
    "    for token_a in text1['token']:\n",
    "        for token_b in text2['token']:\n",
    "            if token_a == token_b and token_b not in similars:\n",
    "                similars.append(token_a)\n",
    "    return similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "115bd9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute dinstances between two DataFrames, based on a list of similar tokens\n",
    "def compute_distances(df1, df2, similars):\n",
    "    distances = []\n",
    "    for token in similars:\n",
    "        if token in df1['token'].values and token in df2['token'].values:\n",
    "            emb1 = torch.tensor(df1[df1['token'] == token].iloc[:, 1:].values.flatten(), dtype=torch.float)\n",
    "            emb2 = torch.tensor(df2[df2['token'] == token].iloc[:, 1:].values.flatten(), dtype=torch.float)\n",
    "            cos_sim = F.cosine_similarity(emb1, emb2, dim=0)\n",
    "            distances.append((token, cos_sim))\n",
    "    return pd.DataFrame(distances, columns=['token', 'distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50de54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bekanntes problem dass die fulltext spalte meherere einzele strings erhält statt einen ganzen\n",
    "string_test= join_strings(data_fullText['fullText'][0])\n",
    "string_check= join_strings(data_fullText['fullText'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc601700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function chunk_text at 0x3082fde10>\n"
     ]
    }
   ],
   "source": [
    "chunks_test = chunk_text_bi(string_test)\n",
    "chunks_check = chunk_text_bi(string_check)\n",
    "print(chunk_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f06391f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 279 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 128 tokens\n"
     ]
    }
   ],
   "source": [
    "df = embTokenDf_bi(chunks_test)\n",
    "df_check = embTokenDf_bi(chunks_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8ac39e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>-0.331984</td>\n",
       "      <td>0.182910</td>\n",
       "      <td>-0.248220</td>\n",
       "      <td>-0.578612</td>\n",
       "      <td>0.374263</td>\n",
       "      <td>-0.419875</td>\n",
       "      <td>0.634523</td>\n",
       "      <td>1.287845</td>\n",
       "      <td>-0.654429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.941082</td>\n",
       "      <td>1.089031</td>\n",
       "      <td>0.271291</td>\n",
       "      <td>-0.235618</td>\n",
       "      <td>0.684201</td>\n",
       "      <td>0.504529</td>\n",
       "      <td>-0.592231</td>\n",
       "      <td>-0.291267</td>\n",
       "      <td>-0.531589</td>\n",
       "      <td>0.813334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>introduction</td>\n",
       "      <td>-0.229607</td>\n",
       "      <td>0.472331</td>\n",
       "      <td>-0.420002</td>\n",
       "      <td>-0.329332</td>\n",
       "      <td>0.869090</td>\n",
       "      <td>-0.387537</td>\n",
       "      <td>0.762768</td>\n",
       "      <td>1.115451</td>\n",
       "      <td>-0.258021</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.123116</td>\n",
       "      <td>1.013114</td>\n",
       "      <td>-0.185675</td>\n",
       "      <td>-0.321305</td>\n",
       "      <td>0.113038</td>\n",
       "      <td>0.375001</td>\n",
       "      <td>-0.708969</td>\n",
       "      <td>0.082410</td>\n",
       "      <td>-0.591021</td>\n",
       "      <td>0.336394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>-0.637772</td>\n",
       "      <td>-0.299904</td>\n",
       "      <td>-0.068341</td>\n",
       "      <td>-0.354077</td>\n",
       "      <td>0.205426</td>\n",
       "      <td>-0.519120</td>\n",
       "      <td>0.751174</td>\n",
       "      <td>0.896734</td>\n",
       "      <td>-0.550310</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.252334</td>\n",
       "      <td>1.123770</td>\n",
       "      <td>0.039461</td>\n",
       "      <td>-0.569271</td>\n",
       "      <td>0.235096</td>\n",
       "      <td>0.207362</td>\n",
       "      <td>-0.669360</td>\n",
       "      <td>0.231235</td>\n",
       "      <td>-0.448930</td>\n",
       "      <td>0.575496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>-0.932534</td>\n",
       "      <td>-0.443429</td>\n",
       "      <td>-0.105964</td>\n",
       "      <td>-0.470870</td>\n",
       "      <td>0.335713</td>\n",
       "      <td>-0.602499</td>\n",
       "      <td>0.717312</td>\n",
       "      <td>0.524212</td>\n",
       "      <td>-0.613316</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.287884</td>\n",
       "      <td>1.388221</td>\n",
       "      <td>0.245366</td>\n",
       "      <td>-0.225503</td>\n",
       "      <td>0.152700</td>\n",
       "      <td>0.729910</td>\n",
       "      <td>-1.102237</td>\n",
       "      <td>0.616262</td>\n",
       "      <td>-0.575144</td>\n",
       "      <td>0.469373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>symposium</td>\n",
       "      <td>-0.968991</td>\n",
       "      <td>0.153379</td>\n",
       "      <td>-0.409553</td>\n",
       "      <td>-0.476401</td>\n",
       "      <td>0.696235</td>\n",
       "      <td>-0.617728</td>\n",
       "      <td>0.453915</td>\n",
       "      <td>0.150342</td>\n",
       "      <td>-0.509858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.610394</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>-0.471686</td>\n",
       "      <td>-0.393526</td>\n",
       "      <td>-0.447391</td>\n",
       "      <td>0.785697</td>\n",
       "      <td>-1.230211</td>\n",
       "      <td>0.024521</td>\n",
       "      <td>-0.485662</td>\n",
       "      <td>0.620657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>##bound</td>\n",
       "      <td>-0.074433</td>\n",
       "      <td>-0.122370</td>\n",
       "      <td>-0.098292</td>\n",
       "      <td>-0.791965</td>\n",
       "      <td>1.404161</td>\n",
       "      <td>-0.978903</td>\n",
       "      <td>0.689625</td>\n",
       "      <td>1.154164</td>\n",
       "      <td>-0.859711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362107</td>\n",
       "      <td>0.512018</td>\n",
       "      <td>0.294348</td>\n",
       "      <td>-0.544874</td>\n",
       "      <td>0.232325</td>\n",
       "      <td>-0.094711</td>\n",
       "      <td>-1.222235</td>\n",
       "      <td>-0.204073</td>\n",
       "      <td>-0.608521</td>\n",
       "      <td>0.161984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>vol</td>\n",
       "      <td>-0.725417</td>\n",
       "      <td>-0.167317</td>\n",
       "      <td>-0.207280</td>\n",
       "      <td>-1.173315</td>\n",
       "      <td>0.716304</td>\n",
       "      <td>-0.696974</td>\n",
       "      <td>0.410055</td>\n",
       "      <td>0.401138</td>\n",
       "      <td>-0.444448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.598452</td>\n",
       "      <td>0.858834</td>\n",
       "      <td>0.047046</td>\n",
       "      <td>-0.409912</td>\n",
       "      <td>-0.343304</td>\n",
       "      <td>0.135056</td>\n",
       "      <td>-1.152168</td>\n",
       "      <td>0.409824</td>\n",
       "      <td>-0.312384</td>\n",
       "      <td>0.525383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>.</td>\n",
       "      <td>-0.524537</td>\n",
       "      <td>-0.270352</td>\n",
       "      <td>0.113892</td>\n",
       "      <td>-0.791958</td>\n",
       "      <td>0.612254</td>\n",
       "      <td>-0.049095</td>\n",
       "      <td>0.326591</td>\n",
       "      <td>0.801209</td>\n",
       "      <td>-0.782507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.688518</td>\n",
       "      <td>0.247434</td>\n",
       "      <td>0.244075</td>\n",
       "      <td>-0.496736</td>\n",
       "      <td>-0.030847</td>\n",
       "      <td>0.151699</td>\n",
       "      <td>-1.099195</td>\n",
       "      <td>-0.150906</td>\n",
       "      <td>-0.546401</td>\n",
       "      <td>0.348904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>114</td>\n",
       "      <td>-0.240468</td>\n",
       "      <td>-0.186169</td>\n",
       "      <td>0.156619</td>\n",
       "      <td>-0.671195</td>\n",
       "      <td>0.561857</td>\n",
       "      <td>-0.415792</td>\n",
       "      <td>0.443125</td>\n",
       "      <td>0.632555</td>\n",
       "      <td>-0.545876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.958988</td>\n",
       "      <td>0.602903</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>-0.647622</td>\n",
       "      <td>-0.367192</td>\n",
       "      <td>0.058959</td>\n",
       "      <td>-0.682652</td>\n",
       "      <td>-0.042493</td>\n",
       "      <td>-0.350372</td>\n",
       "      <td>0.541936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>-0.691458</td>\n",
       "      <td>-0.736855</td>\n",
       "      <td>-0.715999</td>\n",
       "      <td>-1.604810</td>\n",
       "      <td>0.946651</td>\n",
       "      <td>-0.069355</td>\n",
       "      <td>0.184678</td>\n",
       "      <td>0.786378</td>\n",
       "      <td>-0.979826</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.332167</td>\n",
       "      <td>1.118991</td>\n",
       "      <td>0.857454</td>\n",
       "      <td>-1.016397</td>\n",
       "      <td>-0.129669</td>\n",
       "      <td>0.783543</td>\n",
       "      <td>-1.912381</td>\n",
       "      <td>-0.202875</td>\n",
       "      <td>-0.449814</td>\n",
       "      <td>-0.329536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4375 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             token         0         1         2         3         4  \\\n",
       "0            [CLS] -0.331984  0.182910 -0.248220 -0.578612  0.374263   \n",
       "1     introduction -0.229607  0.472331 -0.420002 -0.329332  0.869090   \n",
       "2               to -0.637772 -0.299904 -0.068341 -0.354077  0.205426   \n",
       "3              the -0.932534 -0.443429 -0.105964 -0.470870  0.335713   \n",
       "4        symposium -0.968991  0.153379 -0.409553 -0.476401  0.696235   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4370       ##bound -0.074433 -0.122370 -0.098292 -0.791965  1.404161   \n",
       "4371           vol -0.725417 -0.167317 -0.207280 -1.173315  0.716304   \n",
       "4372             . -0.524537 -0.270352  0.113892 -0.791958  0.612254   \n",
       "4373           114 -0.240468 -0.186169  0.156619 -0.671195  0.561857   \n",
       "4374         [SEP] -0.691458 -0.736855 -0.715999 -1.604810  0.946651   \n",
       "\n",
       "             5         6         7         8  ...       758       759  \\\n",
       "0    -0.419875  0.634523  1.287845 -0.654429  ... -0.941082  1.089031   \n",
       "1    -0.387537  0.762768  1.115451 -0.258021  ... -1.123116  1.013114   \n",
       "2    -0.519120  0.751174  0.896734 -0.550310  ... -1.252334  1.123770   \n",
       "3    -0.602499  0.717312  0.524212 -0.613316  ... -1.287884  1.388221   \n",
       "4    -0.617728  0.453915  0.150342 -0.509858  ... -0.610394  0.961333   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "4370 -0.978903  0.689625  1.154164 -0.859711  ... -0.362107  0.512018   \n",
       "4371 -0.696974  0.410055  0.401138 -0.444448  ... -0.598452  0.858834   \n",
       "4372 -0.049095  0.326591  0.801209 -0.782507  ... -0.688518  0.247434   \n",
       "4373 -0.415792  0.443125  0.632555 -0.545876  ... -0.958988  0.602903   \n",
       "4374 -0.069355  0.184678  0.786378 -0.979826  ... -1.332167  1.118991   \n",
       "\n",
       "           760       761       762       763       764       765       766  \\\n",
       "0     0.271291 -0.235618  0.684201  0.504529 -0.592231 -0.291267 -0.531589   \n",
       "1    -0.185675 -0.321305  0.113038  0.375001 -0.708969  0.082410 -0.591021   \n",
       "2     0.039461 -0.569271  0.235096  0.207362 -0.669360  0.231235 -0.448930   \n",
       "3     0.245366 -0.225503  0.152700  0.729910 -1.102237  0.616262 -0.575144   \n",
       "4    -0.471686 -0.393526 -0.447391  0.785697 -1.230211  0.024521 -0.485662   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4370  0.294348 -0.544874  0.232325 -0.094711 -1.222235 -0.204073 -0.608521   \n",
       "4371  0.047046 -0.409912 -0.343304  0.135056 -1.152168  0.409824 -0.312384   \n",
       "4372  0.244075 -0.496736 -0.030847  0.151699 -1.099195 -0.150906 -0.546401   \n",
       "4373  0.009837 -0.647622 -0.367192  0.058959 -0.682652 -0.042493 -0.350372   \n",
       "4374  0.857454 -1.016397 -0.129669  0.783543 -1.912381 -0.202875 -0.449814   \n",
       "\n",
       "           767  \n",
       "0     0.813334  \n",
       "1     0.336394  \n",
       "2     0.575496  \n",
       "3     0.469373  \n",
       "4     0.620657  \n",
       "...        ...  \n",
       "4370  0.161984  \n",
       "4371  0.525383  \n",
       "4372  0.348904  \n",
       "4373  0.541936  \n",
       "4374 -0.329536  \n",
       "\n",
       "[4375 rows x 769 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff69975c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>-0.344717</td>\n",
       "      <td>-0.135695</td>\n",
       "      <td>-0.269655</td>\n",
       "      <td>-0.064902</td>\n",
       "      <td>0.044204</td>\n",
       "      <td>0.176534</td>\n",
       "      <td>0.196457</td>\n",
       "      <td>-0.178467</td>\n",
       "      <td>0.055168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104664</td>\n",
       "      <td>-0.097730</td>\n",
       "      <td>-0.226245</td>\n",
       "      <td>-0.535290</td>\n",
       "      <td>-0.116922</td>\n",
       "      <td>-0.087427</td>\n",
       "      <td>-0.253659</td>\n",
       "      <td>-0.112412</td>\n",
       "      <td>0.405427</td>\n",
       "      <td>0.338774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hind</td>\n",
       "      <td>-0.138206</td>\n",
       "      <td>0.217037</td>\n",
       "      <td>-0.080569</td>\n",
       "      <td>-0.340516</td>\n",
       "      <td>0.046804</td>\n",
       "      <td>-0.113244</td>\n",
       "      <td>0.213599</td>\n",
       "      <td>0.380986</td>\n",
       "      <td>0.613848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016757</td>\n",
       "      <td>0.155728</td>\n",
       "      <td>-0.201132</td>\n",
       "      <td>-0.177646</td>\n",
       "      <td>0.011423</td>\n",
       "      <td>0.123741</td>\n",
       "      <td>-0.533486</td>\n",
       "      <td>0.206089</td>\n",
       "      <td>0.231340</td>\n",
       "      <td>-0.076606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>##aw</td>\n",
       "      <td>-0.580886</td>\n",
       "      <td>0.348322</td>\n",
       "      <td>-0.249763</td>\n",
       "      <td>-0.072945</td>\n",
       "      <td>0.541737</td>\n",
       "      <td>-0.171324</td>\n",
       "      <td>0.189224</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>0.938491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447191</td>\n",
       "      <td>0.073399</td>\n",
       "      <td>-0.114658</td>\n",
       "      <td>-0.040792</td>\n",
       "      <td>-0.334891</td>\n",
       "      <td>-0.071662</td>\n",
       "      <td>-0.538548</td>\n",
       "      <td>0.158648</td>\n",
       "      <td>0.235514</td>\n",
       "      <td>-0.409985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##i</td>\n",
       "      <td>-0.432546</td>\n",
       "      <td>0.079737</td>\n",
       "      <td>-0.303574</td>\n",
       "      <td>-0.009671</td>\n",
       "      <td>0.386723</td>\n",
       "      <td>0.039037</td>\n",
       "      <td>0.097900</td>\n",
       "      <td>0.243090</td>\n",
       "      <td>-0.145962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181922</td>\n",
       "      <td>0.156452</td>\n",
       "      <td>-0.380030</td>\n",
       "      <td>-0.418463</td>\n",
       "      <td>-0.132771</td>\n",
       "      <td>0.050764</td>\n",
       "      <td>-0.020565</td>\n",
       "      <td>0.206485</td>\n",
       "      <td>0.064828</td>\n",
       "      <td>0.299494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>publishing</td>\n",
       "      <td>-0.330183</td>\n",
       "      <td>0.616249</td>\n",
       "      <td>0.234584</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>0.231249</td>\n",
       "      <td>-0.391734</td>\n",
       "      <td>-0.034025</td>\n",
       "      <td>0.146362</td>\n",
       "      <td>-0.140210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007340</td>\n",
       "      <td>0.068143</td>\n",
       "      <td>-0.483108</td>\n",
       "      <td>-0.651154</td>\n",
       "      <td>-0.175750</td>\n",
       "      <td>-0.027397</td>\n",
       "      <td>0.034670</td>\n",
       "      <td>0.219389</td>\n",
       "      <td>0.148178</td>\n",
       "      <td>0.061312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6779</th>\n",
       "      <td>128</td>\n",
       "      <td>0.119015</td>\n",
       "      <td>0.361266</td>\n",
       "      <td>0.270546</td>\n",
       "      <td>-0.064069</td>\n",
       "      <td>0.379401</td>\n",
       "      <td>-0.470019</td>\n",
       "      <td>0.238333</td>\n",
       "      <td>-0.694087</td>\n",
       "      <td>0.563587</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341229</td>\n",
       "      <td>0.310049</td>\n",
       "      <td>-0.351117</td>\n",
       "      <td>-0.515020</td>\n",
       "      <td>-0.169318</td>\n",
       "      <td>-0.437265</td>\n",
       "      <td>-0.165990</td>\n",
       "      <td>0.006687</td>\n",
       "      <td>0.045813</td>\n",
       "      <td>0.028579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6780</th>\n",
       "      <td>,</td>\n",
       "      <td>-0.991199</td>\n",
       "      <td>-0.095221</td>\n",
       "      <td>0.215858</td>\n",
       "      <td>0.618528</td>\n",
       "      <td>0.197720</td>\n",
       "      <td>-0.061087</td>\n",
       "      <td>0.283250</td>\n",
       "      <td>0.544975</td>\n",
       "      <td>-0.257395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128828</td>\n",
       "      <td>-0.046993</td>\n",
       "      <td>-0.546233</td>\n",
       "      <td>-0.425803</td>\n",
       "      <td>-0.249981</td>\n",
       "      <td>-0.532426</td>\n",
       "      <td>-0.135489</td>\n",
       "      <td>0.145354</td>\n",
       "      <td>0.198204</td>\n",
       "      <td>0.302158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>1992</td>\n",
       "      <td>-0.126286</td>\n",
       "      <td>0.318318</td>\n",
       "      <td>0.408300</td>\n",
       "      <td>-0.009114</td>\n",
       "      <td>0.257059</td>\n",
       "      <td>-0.245588</td>\n",
       "      <td>0.383461</td>\n",
       "      <td>0.168673</td>\n",
       "      <td>0.399108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276631</td>\n",
       "      <td>0.340496</td>\n",
       "      <td>-1.028845</td>\n",
       "      <td>0.047639</td>\n",
       "      <td>-0.375134</td>\n",
       "      <td>-0.492284</td>\n",
       "      <td>-0.153766</td>\n",
       "      <td>0.228452</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>-0.267242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6782</th>\n",
       "      <td>.</td>\n",
       "      <td>-1.064659</td>\n",
       "      <td>-0.900344</td>\n",
       "      <td>-0.222486</td>\n",
       "      <td>0.076515</td>\n",
       "      <td>0.414097</td>\n",
       "      <td>0.114952</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.390113</td>\n",
       "      <td>-0.291600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467118</td>\n",
       "      <td>-0.144965</td>\n",
       "      <td>-0.279765</td>\n",
       "      <td>-0.385280</td>\n",
       "      <td>-0.149901</td>\n",
       "      <td>-0.284415</td>\n",
       "      <td>-0.310129</td>\n",
       "      <td>0.726733</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>0.059180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6783</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>-0.667975</td>\n",
       "      <td>-0.172845</td>\n",
       "      <td>-0.721269</td>\n",
       "      <td>0.368649</td>\n",
       "      <td>0.038622</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.317106</td>\n",
       "      <td>0.653178</td>\n",
       "      <td>-0.455541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013386</td>\n",
       "      <td>-0.253619</td>\n",
       "      <td>-1.265747</td>\n",
       "      <td>-1.075615</td>\n",
       "      <td>-0.487794</td>\n",
       "      <td>-0.820371</td>\n",
       "      <td>-0.550929</td>\n",
       "      <td>0.396645</td>\n",
       "      <td>-0.455393</td>\n",
       "      <td>-0.149665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6784 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           token         0         1         2         3         4         5  \\\n",
       "0          [CLS] -0.344717 -0.135695 -0.269655 -0.064902  0.044204  0.176534   \n",
       "1           hind -0.138206  0.217037 -0.080569 -0.340516  0.046804 -0.113244   \n",
       "2           ##aw -0.580886  0.348322 -0.249763 -0.072945  0.541737 -0.171324   \n",
       "3            ##i -0.432546  0.079737 -0.303574 -0.009671  0.386723  0.039037   \n",
       "4     publishing -0.330183  0.616249  0.234584  0.003164  0.231249 -0.391734   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "6779         128  0.119015  0.361266  0.270546 -0.064069  0.379401 -0.470019   \n",
       "6780           , -0.991199 -0.095221  0.215858  0.618528  0.197720 -0.061087   \n",
       "6781        1992 -0.126286  0.318318  0.408300 -0.009114  0.257059 -0.245588   \n",
       "6782           . -1.064659 -0.900344 -0.222486  0.076515  0.414097  0.114952   \n",
       "6783       [SEP] -0.667975 -0.172845 -0.721269  0.368649  0.038622  0.000255   \n",
       "\n",
       "             6         7         8  ...       758       759       760  \\\n",
       "0     0.196457 -0.178467  0.055168  ...  0.104664 -0.097730 -0.226245   \n",
       "1     0.213599  0.380986  0.613848  ...  0.016757  0.155728 -0.201132   \n",
       "2     0.189224  0.295073  0.938491  ... -0.447191  0.073399 -0.114658   \n",
       "3     0.097900  0.243090 -0.145962  ... -0.181922  0.156452 -0.380030   \n",
       "4    -0.034025  0.146362 -0.140210  ...  0.007340  0.068143 -0.483108   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6779  0.238333 -0.694087  0.563587  ... -0.341229  0.310049 -0.351117   \n",
       "6780  0.283250  0.544975 -0.257395  ...  0.128828 -0.046993 -0.546233   \n",
       "6781  0.383461  0.168673  0.399108  ... -0.276631  0.340496 -1.028845   \n",
       "6782  0.004499  0.390113 -0.291600  ...  0.467118 -0.144965 -0.279765   \n",
       "6783  0.317106  0.653178 -0.455541  ...  0.013386 -0.253619 -1.265747   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0    -0.535290 -0.116922 -0.087427 -0.253659 -0.112412  0.405427  0.338774  \n",
       "1    -0.177646  0.011423  0.123741 -0.533486  0.206089  0.231340 -0.076606  \n",
       "2    -0.040792 -0.334891 -0.071662 -0.538548  0.158648  0.235514 -0.409985  \n",
       "3    -0.418463 -0.132771  0.050764 -0.020565  0.206485  0.064828  0.299494  \n",
       "4    -0.651154 -0.175750 -0.027397  0.034670  0.219389  0.148178  0.061312  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6779 -0.515020 -0.169318 -0.437265 -0.165990  0.006687  0.045813  0.028579  \n",
       "6780 -0.425803 -0.249981 -0.532426 -0.135489  0.145354  0.198204  0.302158  \n",
       "6781  0.047639 -0.375134 -0.492284 -0.153766  0.228452 -0.083912 -0.267242  \n",
       "6782 -0.385280 -0.149901 -0.284415 -0.310129  0.726733 -0.000837  0.059180  \n",
       "6783 -1.075615 -0.487794 -0.820371 -0.550929  0.396645 -0.455393 -0.149665  \n",
       "\n",
       "[6784 rows x 769 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27678c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3364375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e23c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5216896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_check.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3367ade1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similars = check_similars(df, df_check)\n",
    "len(similars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "37bde16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>academic</td>\n",
       "      <td>-0.601265</td>\n",
       "      <td>0.828746</td>\n",
       "      <td>0.029098</td>\n",
       "      <td>-0.035453</td>\n",
       "      <td>0.17885</td>\n",
       "      <td>0.217117</td>\n",
       "      <td>-0.06686</td>\n",
       "      <td>0.413646</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15827</td>\n",
       "      <td>0.487397</td>\n",
       "      <td>-0.176172</td>\n",
       "      <td>-0.337464</td>\n",
       "      <td>-0.154993</td>\n",
       "      <td>-0.388852</td>\n",
       "      <td>-0.27229</td>\n",
       "      <td>0.310074</td>\n",
       "      <td>0.088256</td>\n",
       "      <td>-0.137603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         token         0         1         2         3        4         5  \\\n",
       "3131  academic -0.601265  0.828746  0.029098 -0.035453  0.17885  0.217117   \n",
       "\n",
       "            6         7         8  ...      758       759       760       761  \\\n",
       "3131 -0.06686  0.413646  0.317597  ... -0.15827  0.487397 -0.176172 -0.337464   \n",
       "\n",
       "           762       763      764       765       766       767  \n",
       "3131 -0.154993 -0.388852 -0.27229  0.310074  0.088256 -0.137603  \n",
       "\n",
       "[1 rows x 769 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_t1_0 = df.loc[df['token']== \"academic\"]\n",
    "academic_t1_0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9af8ac8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>academic</td>\n",
       "      <td>-1.125821</td>\n",
       "      <td>0.235547</td>\n",
       "      <td>-0.043250</td>\n",
       "      <td>0.131551</td>\n",
       "      <td>-0.046669</td>\n",
       "      <td>0.216709</td>\n",
       "      <td>-0.250712</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.492123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095010</td>\n",
       "      <td>-0.038550</td>\n",
       "      <td>0.020674</td>\n",
       "      <td>-0.614497</td>\n",
       "      <td>-0.504885</td>\n",
       "      <td>-0.320778</td>\n",
       "      <td>-0.702176</td>\n",
       "      <td>0.338276</td>\n",
       "      <td>0.013796</td>\n",
       "      <td>-0.026589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>academic</td>\n",
       "      <td>-0.361622</td>\n",
       "      <td>0.388464</td>\n",
       "      <td>0.014788</td>\n",
       "      <td>0.198048</td>\n",
       "      <td>0.194823</td>\n",
       "      <td>0.367066</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.382446</td>\n",
       "      <td>0.385886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081263</td>\n",
       "      <td>0.120075</td>\n",
       "      <td>0.170643</td>\n",
       "      <td>-0.189056</td>\n",
       "      <td>-0.269455</td>\n",
       "      <td>-0.356648</td>\n",
       "      <td>-0.206874</td>\n",
       "      <td>-0.436759</td>\n",
       "      <td>0.078009</td>\n",
       "      <td>0.135084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         token         0         1         2         3         4         5  \\\n",
       "149   academic -1.125821  0.235547 -0.043250  0.131551 -0.046669  0.216709   \n",
       "4680  academic -0.361622  0.388464  0.014788  0.198048  0.194823  0.367066   \n",
       "\n",
       "             6         7         8  ...       758       759       760  \\\n",
       "149  -0.250712  0.312500  0.492123  ...  0.095010 -0.038550  0.020674   \n",
       "4680  0.061700  0.382446  0.385886  ... -0.081263  0.120075  0.170643   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "149  -0.614497 -0.504885 -0.320778 -0.702176  0.338276  0.013796 -0.026589  \n",
       "4680 -0.189056 -0.269455 -0.356648 -0.206874 -0.436759  0.078009  0.135084  \n",
       "\n",
       "[2 rows x 769 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_t2_0= df_check[df_check\n",
    "      ['token'] == \"academic\"]\n",
    "academic_t2_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e8c56644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#</td>\n",
       "      <td>-0.450449</td>\n",
       "      <td>0.060584</td>\n",
       "      <td>0.467251</td>\n",
       "      <td>0.040403</td>\n",
       "      <td>0.036333</td>\n",
       "      <td>-0.054870</td>\n",
       "      <td>0.165150</td>\n",
       "      <td>0.080210</td>\n",
       "      <td>-0.191602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342114</td>\n",
       "      <td>0.199850</td>\n",
       "      <td>-0.032674</td>\n",
       "      <td>-0.488435</td>\n",
       "      <td>0.014099</td>\n",
       "      <td>-0.521700</td>\n",
       "      <td>-0.036816</td>\n",
       "      <td>0.300840</td>\n",
       "      <td>0.325626</td>\n",
       "      <td>0.490635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>##10</td>\n",
       "      <td>0.770036</td>\n",
       "      <td>-0.072898</td>\n",
       "      <td>-0.011950</td>\n",
       "      <td>0.096020</td>\n",
       "      <td>0.521422</td>\n",
       "      <td>0.314781</td>\n",
       "      <td>-0.112351</td>\n",
       "      <td>0.125385</td>\n",
       "      <td>-0.274287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030181</td>\n",
       "      <td>-0.254268</td>\n",
       "      <td>-0.089963</td>\n",
       "      <td>-0.189089</td>\n",
       "      <td>0.297410</td>\n",
       "      <td>-0.379630</td>\n",
       "      <td>-0.594522</td>\n",
       "      <td>0.098798</td>\n",
       "      <td>-0.120006</td>\n",
       "      <td>-0.294954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>##13</td>\n",
       "      <td>0.478097</td>\n",
       "      <td>0.207713</td>\n",
       "      <td>0.373633</td>\n",
       "      <td>0.135911</td>\n",
       "      <td>0.463529</td>\n",
       "      <td>-0.086371</td>\n",
       "      <td>-0.106634</td>\n",
       "      <td>-0.074644</td>\n",
       "      <td>0.111880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039257</td>\n",
       "      <td>0.188831</td>\n",
       "      <td>0.124511</td>\n",
       "      <td>-0.229363</td>\n",
       "      <td>0.329342</td>\n",
       "      <td>-0.030861</td>\n",
       "      <td>0.227609</td>\n",
       "      <td>-0.174830</td>\n",
       "      <td>-0.346342</td>\n",
       "      <td>-0.164216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##2</td>\n",
       "      <td>-0.125490</td>\n",
       "      <td>-0.319575</td>\n",
       "      <td>0.173975</td>\n",
       "      <td>-0.115178</td>\n",
       "      <td>0.321029</td>\n",
       "      <td>-0.445602</td>\n",
       "      <td>0.349599</td>\n",
       "      <td>0.395488</td>\n",
       "      <td>-0.080770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128789</td>\n",
       "      <td>0.974438</td>\n",
       "      <td>0.347023</td>\n",
       "      <td>-1.103901</td>\n",
       "      <td>0.174664</td>\n",
       "      <td>-0.411868</td>\n",
       "      <td>0.172614</td>\n",
       "      <td>-0.177772</td>\n",
       "      <td>-0.074557</td>\n",
       "      <td>-0.158136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>##3</td>\n",
       "      <td>-0.039455</td>\n",
       "      <td>0.039888</td>\n",
       "      <td>0.290958</td>\n",
       "      <td>-0.325974</td>\n",
       "      <td>0.127569</td>\n",
       "      <td>-0.542703</td>\n",
       "      <td>0.367787</td>\n",
       "      <td>-0.152513</td>\n",
       "      <td>0.178206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286158</td>\n",
       "      <td>0.748861</td>\n",
       "      <td>0.135050</td>\n",
       "      <td>-0.689556</td>\n",
       "      <td>0.162270</td>\n",
       "      <td>-0.104994</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>-0.150362</td>\n",
       "      <td>-0.132143</td>\n",
       "      <td>0.093124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>‐</td>\n",
       "      <td>-0.020358</td>\n",
       "      <td>0.025302</td>\n",
       "      <td>0.215241</td>\n",
       "      <td>0.128445</td>\n",
       "      <td>0.229219</td>\n",
       "      <td>-0.004710</td>\n",
       "      <td>-0.114489</td>\n",
       "      <td>-0.217625</td>\n",
       "      <td>-0.006214</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038104</td>\n",
       "      <td>0.081021</td>\n",
       "      <td>-0.376385</td>\n",
       "      <td>-0.258840</td>\n",
       "      <td>0.039387</td>\n",
       "      <td>-0.069169</td>\n",
       "      <td>-0.014814</td>\n",
       "      <td>0.228515</td>\n",
       "      <td>0.038939</td>\n",
       "      <td>0.466118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>—</td>\n",
       "      <td>-0.196129</td>\n",
       "      <td>0.154295</td>\n",
       "      <td>0.224556</td>\n",
       "      <td>-0.009453</td>\n",
       "      <td>0.220481</td>\n",
       "      <td>-0.053027</td>\n",
       "      <td>-0.092431</td>\n",
       "      <td>-0.084107</td>\n",
       "      <td>0.138539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042408</td>\n",
       "      <td>-0.044590</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>-0.161538</td>\n",
       "      <td>0.030274</td>\n",
       "      <td>-0.183313</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>0.215381</td>\n",
       "      <td>-0.041085</td>\n",
       "      <td>0.299305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>’</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.013919</td>\n",
       "      <td>0.523327</td>\n",
       "      <td>-0.240754</td>\n",
       "      <td>0.180680</td>\n",
       "      <td>-0.175062</td>\n",
       "      <td>0.350394</td>\n",
       "      <td>0.189871</td>\n",
       "      <td>-0.173764</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048633</td>\n",
       "      <td>0.197551</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>-0.607778</td>\n",
       "      <td>0.042540</td>\n",
       "      <td>-0.349999</td>\n",
       "      <td>0.339385</td>\n",
       "      <td>-0.005191</td>\n",
       "      <td>0.014662</td>\n",
       "      <td>-0.223171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>“</td>\n",
       "      <td>-0.143035</td>\n",
       "      <td>-0.104549</td>\n",
       "      <td>0.288424</td>\n",
       "      <td>-0.044611</td>\n",
       "      <td>0.340385</td>\n",
       "      <td>0.090808</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.101467</td>\n",
       "      <td>-0.054791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045224</td>\n",
       "      <td>0.181153</td>\n",
       "      <td>0.121511</td>\n",
       "      <td>-0.109075</td>\n",
       "      <td>0.019695</td>\n",
       "      <td>-0.255275</td>\n",
       "      <td>0.016315</td>\n",
       "      <td>-0.082925</td>\n",
       "      <td>-0.153490</td>\n",
       "      <td>-0.112157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>”</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.027002</td>\n",
       "      <td>0.263894</td>\n",
       "      <td>-0.066341</td>\n",
       "      <td>0.116847</td>\n",
       "      <td>0.013391</td>\n",
       "      <td>-0.044716</td>\n",
       "      <td>0.033328</td>\n",
       "      <td>0.120658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137196</td>\n",
       "      <td>-0.007688</td>\n",
       "      <td>-0.125593</td>\n",
       "      <td>-0.137727</td>\n",
       "      <td>-0.112175</td>\n",
       "      <td>-0.187317</td>\n",
       "      <td>0.107989</td>\n",
       "      <td>0.095422</td>\n",
       "      <td>-0.055184</td>\n",
       "      <td>-0.033093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1418 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     token         0         1         2         3         4         5  \\\n",
       "0        # -0.450449  0.060584  0.467251  0.040403  0.036333 -0.054870   \n",
       "1     ##10  0.770036 -0.072898 -0.011950  0.096020  0.521422  0.314781   \n",
       "2     ##13  0.478097  0.207713  0.373633  0.135911  0.463529 -0.086371   \n",
       "3      ##2 -0.125490 -0.319575  0.173975 -0.115178  0.321029 -0.445602   \n",
       "4      ##3 -0.039455  0.039888  0.290958 -0.325974  0.127569 -0.542703   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "1413     ‐ -0.020358  0.025302  0.215241  0.128445  0.229219 -0.004710   \n",
       "1414     — -0.196129  0.154295  0.224556 -0.009453  0.220481 -0.053027   \n",
       "1415     ’ -0.000578 -0.013919  0.523327 -0.240754  0.180680 -0.175062   \n",
       "1416     “ -0.143035 -0.104549  0.288424 -0.044611  0.340385  0.090808   \n",
       "1417     ”  0.002408  0.027002  0.263894 -0.066341  0.116847  0.013391   \n",
       "\n",
       "             6         7         8  ...       758       759       760  \\\n",
       "0     0.165150  0.080210 -0.191602  ...  0.342114  0.199850 -0.032674   \n",
       "1    -0.112351  0.125385 -0.274287  ...  0.030181 -0.254268 -0.089963   \n",
       "2    -0.106634 -0.074644  0.111880  ... -0.039257  0.188831  0.124511   \n",
       "3     0.349599  0.395488 -0.080770  ...  0.128789  0.974438  0.347023   \n",
       "4     0.367787 -0.152513  0.178206  ... -0.286158  0.748861  0.135050   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1413 -0.114489 -0.217625 -0.006214  ... -0.038104  0.081021 -0.376385   \n",
       "1414 -0.092431 -0.084107  0.138539  ...  0.042408 -0.044590  0.002100   \n",
       "1415  0.350394  0.189871 -0.173764  ... -0.048633  0.197551  0.076379   \n",
       "1416  0.042969  0.101467 -0.054791  ...  0.045224  0.181153  0.121511   \n",
       "1417 -0.044716  0.033328  0.120658  ...  0.137196 -0.007688 -0.125593   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0    -0.488435  0.014099 -0.521700 -0.036816  0.300840  0.325626  0.490635  \n",
       "1    -0.189089  0.297410 -0.379630 -0.594522  0.098798 -0.120006 -0.294954  \n",
       "2    -0.229363  0.329342 -0.030861  0.227609 -0.174830 -0.346342 -0.164216  \n",
       "3    -1.103901  0.174664 -0.411868  0.172614 -0.177772 -0.074557 -0.158136  \n",
       "4    -0.689556  0.162270 -0.104994 -0.001938 -0.150362 -0.132143  0.093124  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1413 -0.258840  0.039387 -0.069169 -0.014814  0.228515  0.038939  0.466118  \n",
       "1414 -0.161538  0.030274 -0.183313  0.047545  0.215381 -0.041085  0.299305  \n",
       "1415 -0.607778  0.042540 -0.349999  0.339385 -0.005191  0.014662 -0.223171  \n",
       "1416 -0.109075  0.019695 -0.255275  0.016315 -0.082925 -0.153490 -0.112157  \n",
       "1417 -0.137727 -0.112175 -0.187317  0.107989  0.095422 -0.055184 -0.033093  \n",
       "\n",
       "[1418 rows x 769 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_t1 = average_token_embeddings(df)\n",
    "df_avg_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c23afe5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#</td>\n",
       "      <td>-0.563808</td>\n",
       "      <td>0.180179</td>\n",
       "      <td>0.231656</td>\n",
       "      <td>0.089228</td>\n",
       "      <td>0.208545</td>\n",
       "      <td>-0.037089</td>\n",
       "      <td>0.250994</td>\n",
       "      <td>0.195309</td>\n",
       "      <td>-0.360223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268769</td>\n",
       "      <td>0.211251</td>\n",
       "      <td>-0.252017</td>\n",
       "      <td>-0.642645</td>\n",
       "      <td>-0.009715</td>\n",
       "      <td>-0.589675</td>\n",
       "      <td>0.024325</td>\n",
       "      <td>0.320372</td>\n",
       "      <td>-0.047912</td>\n",
       "      <td>0.797362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>##0</td>\n",
       "      <td>-0.156132</td>\n",
       "      <td>-0.249740</td>\n",
       "      <td>0.304016</td>\n",
       "      <td>-0.329771</td>\n",
       "      <td>0.724948</td>\n",
       "      <td>0.173097</td>\n",
       "      <td>-0.325669</td>\n",
       "      <td>0.521675</td>\n",
       "      <td>-0.317101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.331157</td>\n",
       "      <td>0.453435</td>\n",
       "      <td>0.041314</td>\n",
       "      <td>-0.962747</td>\n",
       "      <td>0.164895</td>\n",
       "      <td>-0.157524</td>\n",
       "      <td>0.165221</td>\n",
       "      <td>0.054725</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>-0.420054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>##1</td>\n",
       "      <td>-0.560066</td>\n",
       "      <td>0.110436</td>\n",
       "      <td>0.035009</td>\n",
       "      <td>-0.093096</td>\n",
       "      <td>0.251191</td>\n",
       "      <td>-0.389341</td>\n",
       "      <td>0.139701</td>\n",
       "      <td>0.222104</td>\n",
       "      <td>-0.302570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171223</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.035898</td>\n",
       "      <td>-0.585873</td>\n",
       "      <td>-0.055059</td>\n",
       "      <td>-0.118276</td>\n",
       "      <td>0.255495</td>\n",
       "      <td>0.206654</td>\n",
       "      <td>0.130966</td>\n",
       "      <td>0.030419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##2</td>\n",
       "      <td>-0.318209</td>\n",
       "      <td>-0.350751</td>\n",
       "      <td>0.126368</td>\n",
       "      <td>-0.037951</td>\n",
       "      <td>0.144070</td>\n",
       "      <td>-0.196449</td>\n",
       "      <td>0.209988</td>\n",
       "      <td>-0.086515</td>\n",
       "      <td>-0.301521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.794768</td>\n",
       "      <td>-0.093703</td>\n",
       "      <td>-0.976211</td>\n",
       "      <td>-0.052803</td>\n",
       "      <td>-0.257282</td>\n",
       "      <td>0.166780</td>\n",
       "      <td>0.263252</td>\n",
       "      <td>0.098198</td>\n",
       "      <td>-0.016744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>##3</td>\n",
       "      <td>-0.302513</td>\n",
       "      <td>-0.003509</td>\n",
       "      <td>0.215827</td>\n",
       "      <td>-0.230425</td>\n",
       "      <td>0.042920</td>\n",
       "      <td>-0.389191</td>\n",
       "      <td>0.344402</td>\n",
       "      <td>-0.267853</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114494</td>\n",
       "      <td>0.772382</td>\n",
       "      <td>0.017785</td>\n",
       "      <td>-0.803362</td>\n",
       "      <td>0.095049</td>\n",
       "      <td>-0.019696</td>\n",
       "      <td>0.160604</td>\n",
       "      <td>0.122445</td>\n",
       "      <td>-0.015165</td>\n",
       "      <td>-0.100422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>’</td>\n",
       "      <td>0.100034</td>\n",
       "      <td>-0.077991</td>\n",
       "      <td>0.478378</td>\n",
       "      <td>-0.292353</td>\n",
       "      <td>0.428092</td>\n",
       "      <td>0.007119</td>\n",
       "      <td>0.622906</td>\n",
       "      <td>0.042052</td>\n",
       "      <td>-0.091539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186928</td>\n",
       "      <td>-0.135818</td>\n",
       "      <td>0.068261</td>\n",
       "      <td>-0.445195</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>-0.137165</td>\n",
       "      <td>0.166252</td>\n",
       "      <td>-0.195304</td>\n",
       "      <td>0.143982</td>\n",
       "      <td>-0.120265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>“</td>\n",
       "      <td>-0.197380</td>\n",
       "      <td>-0.025060</td>\n",
       "      <td>0.027395</td>\n",
       "      <td>-0.096037</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.147257</td>\n",
       "      <td>-0.044353</td>\n",
       "      <td>-0.249629</td>\n",
       "      <td>0.082819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036749</td>\n",
       "      <td>0.306501</td>\n",
       "      <td>-0.155469</td>\n",
       "      <td>-0.344680</td>\n",
       "      <td>-0.184278</td>\n",
       "      <td>-0.148658</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>-0.008491</td>\n",
       "      <td>-0.161462</td>\n",
       "      <td>0.199885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>”</td>\n",
       "      <td>-0.041589</td>\n",
       "      <td>-0.025265</td>\n",
       "      <td>0.122661</td>\n",
       "      <td>-0.062645</td>\n",
       "      <td>0.143319</td>\n",
       "      <td>0.140707</td>\n",
       "      <td>0.023253</td>\n",
       "      <td>-0.347520</td>\n",
       "      <td>0.249760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101359</td>\n",
       "      <td>0.139857</td>\n",
       "      <td>-0.202278</td>\n",
       "      <td>-0.344078</td>\n",
       "      <td>-0.158291</td>\n",
       "      <td>-0.105505</td>\n",
       "      <td>-0.071328</td>\n",
       "      <td>0.073570</td>\n",
       "      <td>-0.044476</td>\n",
       "      <td>0.155926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>∗</td>\n",
       "      <td>0.602140</td>\n",
       "      <td>0.229147</td>\n",
       "      <td>0.432905</td>\n",
       "      <td>-0.331674</td>\n",
       "      <td>0.045714</td>\n",
       "      <td>-0.005562</td>\n",
       "      <td>0.236791</td>\n",
       "      <td>-0.561777</td>\n",
       "      <td>0.545718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779583</td>\n",
       "      <td>-0.181692</td>\n",
       "      <td>-0.097743</td>\n",
       "      <td>0.413511</td>\n",
       "      <td>-0.045973</td>\n",
       "      <td>-0.111041</td>\n",
       "      <td>-0.476897</td>\n",
       "      <td>-0.080716</td>\n",
       "      <td>-0.192220</td>\n",
       "      <td>-0.061217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>≤</td>\n",
       "      <td>0.138806</td>\n",
       "      <td>0.153082</td>\n",
       "      <td>0.609442</td>\n",
       "      <td>-0.205529</td>\n",
       "      <td>0.344685</td>\n",
       "      <td>-0.165237</td>\n",
       "      <td>0.621211</td>\n",
       "      <td>0.020418</td>\n",
       "      <td>-0.122924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.367758</td>\n",
       "      <td>0.260301</td>\n",
       "      <td>0.139250</td>\n",
       "      <td>-0.108321</td>\n",
       "      <td>-0.015254</td>\n",
       "      <td>-0.013338</td>\n",
       "      <td>-0.336260</td>\n",
       "      <td>0.018840</td>\n",
       "      <td>0.025707</td>\n",
       "      <td>0.445664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1359 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     token         0         1         2         3         4         5  \\\n",
       "0        # -0.563808  0.180179  0.231656  0.089228  0.208545 -0.037089   \n",
       "1      ##0 -0.156132 -0.249740  0.304016 -0.329771  0.724948  0.173097   \n",
       "2      ##1 -0.560066  0.110436  0.035009 -0.093096  0.251191 -0.389341   \n",
       "3      ##2 -0.318209 -0.350751  0.126368 -0.037951  0.144070 -0.196449   \n",
       "4      ##3 -0.302513 -0.003509  0.215827 -0.230425  0.042920 -0.389191   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "1354     ’  0.100034 -0.077991  0.478378 -0.292353  0.428092  0.007119   \n",
       "1355     “ -0.197380 -0.025060  0.027395 -0.096037  0.260374  0.147257   \n",
       "1356     ” -0.041589 -0.025265  0.122661 -0.062645  0.143319  0.140707   \n",
       "1357     ∗  0.602140  0.229147  0.432905 -0.331674  0.045714 -0.005562   \n",
       "1358     ≤  0.138806  0.153082  0.609442 -0.205529  0.344685 -0.165237   \n",
       "\n",
       "             6         7         8  ...       758       759       760  \\\n",
       "0     0.250994  0.195309 -0.360223  ...  0.268769  0.211251 -0.252017   \n",
       "1    -0.325669  0.521675 -0.317101  ... -0.331157  0.453435  0.041314   \n",
       "2     0.139701  0.222104 -0.302570  ... -0.171223  0.465631  0.035898   \n",
       "3     0.209988 -0.086515 -0.301521  ...  0.005166  0.794768 -0.093703   \n",
       "4     0.344402 -0.267853  0.013008  ... -0.114494  0.772382  0.017785   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1354  0.622906  0.042052 -0.091539  ... -0.186928 -0.135818  0.068261   \n",
       "1355 -0.044353 -0.249629  0.082819  ...  0.036749  0.306501 -0.155469   \n",
       "1356  0.023253 -0.347520  0.249760  ...  0.101359  0.139857 -0.202278   \n",
       "1357  0.236791 -0.561777  0.545718  ... -0.779583 -0.181692 -0.097743   \n",
       "1358  0.621211  0.020418 -0.122924  ... -0.367758  0.260301  0.139250   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0    -0.642645 -0.009715 -0.589675  0.024325  0.320372 -0.047912  0.797362  \n",
       "1    -0.962747  0.164895 -0.157524  0.165221  0.054725  0.015162 -0.420054  \n",
       "2    -0.585873 -0.055059 -0.118276  0.255495  0.206654  0.130966  0.030419  \n",
       "3    -0.976211 -0.052803 -0.257282  0.166780  0.263252  0.098198 -0.016744  \n",
       "4    -0.803362  0.095049 -0.019696  0.160604  0.122445 -0.015165 -0.100422  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1354 -0.445195 -0.230130 -0.137165  0.166252 -0.195304  0.143982 -0.120265  \n",
       "1355 -0.344680 -0.184278 -0.148658  0.007700 -0.008491 -0.161462  0.199885  \n",
       "1356 -0.344078 -0.158291 -0.105505 -0.071328  0.073570 -0.044476  0.155926  \n",
       "1357  0.413511 -0.045973 -0.111041 -0.476897 -0.080716 -0.192220 -0.061217  \n",
       "1358 -0.108321 -0.015254 -0.013338 -0.336260  0.018840  0.025707  0.445664  \n",
       "\n",
       "[1359 rows x 769 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_t2 = average_token_embeddings(df_check)\n",
    "df_avg_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "327c2e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>academic</td>\n",
       "      <td>-0.601265</td>\n",
       "      <td>0.828746</td>\n",
       "      <td>0.029098</td>\n",
       "      <td>-0.035453</td>\n",
       "      <td>0.17885</td>\n",
       "      <td>0.217117</td>\n",
       "      <td>-0.06686</td>\n",
       "      <td>0.413646</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15827</td>\n",
       "      <td>0.487397</td>\n",
       "      <td>-0.176172</td>\n",
       "      <td>-0.337464</td>\n",
       "      <td>-0.154993</td>\n",
       "      <td>-0.388852</td>\n",
       "      <td>-0.27229</td>\n",
       "      <td>0.310074</td>\n",
       "      <td>0.088256</td>\n",
       "      <td>-0.137603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        token         0         1         2         3        4         5  \\\n",
       "347  academic -0.601265  0.828746  0.029098 -0.035453  0.17885  0.217117   \n",
       "\n",
       "           6         7         8  ...      758       759       760       761  \\\n",
       "347 -0.06686  0.413646  0.317597  ... -0.15827  0.487397 -0.176172 -0.337464   \n",
       "\n",
       "          762       763      764       765       766       767  \n",
       "347 -0.154993 -0.388852 -0.27229  0.310074  0.088256 -0.137603  \n",
       "\n",
       "[1 rows x 769 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_t1 = df_avg_t1.loc[df_avg_t1['token']== \"academic\"]\n",
    "academic_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "08b139e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>academic</td>\n",
       "      <td>-0.743722</td>\n",
       "      <td>0.312005</td>\n",
       "      <td>-0.014231</td>\n",
       "      <td>0.164799</td>\n",
       "      <td>0.074077</td>\n",
       "      <td>0.291888</td>\n",
       "      <td>-0.094506</td>\n",
       "      <td>0.347473</td>\n",
       "      <td>0.439005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.040763</td>\n",
       "      <td>0.095658</td>\n",
       "      <td>-0.401776</td>\n",
       "      <td>-0.38717</td>\n",
       "      <td>-0.338713</td>\n",
       "      <td>-0.454525</td>\n",
       "      <td>-0.049242</td>\n",
       "      <td>0.045903</td>\n",
       "      <td>0.054247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        token         0         1         2         3         4         5  \\\n",
       "434  academic -0.743722  0.312005 -0.014231  0.164799  0.074077  0.291888   \n",
       "\n",
       "            6         7         8  ...       758       759       760  \\\n",
       "434 -0.094506  0.347473  0.439005  ...  0.006873  0.040763  0.095658   \n",
       "\n",
       "          761      762       763       764       765       766       767  \n",
       "434 -0.401776 -0.38717 -0.338713 -0.454525 -0.049242  0.045903  0.054247  \n",
       "\n",
       "[1 rows x 769 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_t2 = df_avg_t2.loc[df_avg_t2['token']== \"academic\"]\n",
    "academic_t2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dd333b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.01265430e-01,  8.28746378e-01,  2.90977359e-02,\n",
       "        -3.54532562e-02,  1.78849503e-01,  2.17117250e-01,\n",
       "        -6.68595433e-02,  4.13646132e-01,  3.17596704e-01,\n",
       "         1.82884671e-02, -3.64513129e-01,  1.42819136e-01,\n",
       "         3.29290003e-01,  3.04072857e-01,  6.85278401e-02,\n",
       "         4.86486077e-01,  1.04137301e-01, -4.83656466e-01,\n",
       "         8.59485790e-02, -5.32940216e-02, -1.27349257e-01,\n",
       "         2.40941614e-01,  4.59310234e-01,  6.14904106e-01,\n",
       "        -1.88572258e-02, -4.08027470e-01,  9.45716724e-03,\n",
       "         5.50365925e-01, -1.01134226e-01,  1.88127354e-01,\n",
       "         5.50970614e-01,  1.37102291e-01, -5.57745874e-01,\n",
       "         4.61296320e-01, -2.82729983e-01,  1.22586474e-01,\n",
       "        -4.63896692e-01,  1.94146603e-01, -1.37064993e-01,\n",
       "         5.14785171e-01, -1.68440595e-01, -1.10632777e-02,\n",
       "        -9.47741568e-01,  3.36277246e-01, -1.13622583e-01,\n",
       "        -1.92583963e-01,  7.58710504e-02,  8.32067072e-01,\n",
       "        -2.90181994e-01,  6.07975006e-01, -6.67002618e-01,\n",
       "         3.10417503e-01, -1.55079409e-01,  5.71518019e-02,\n",
       "        -1.99387982e-01,  4.33289498e-01,  3.98743488e-02,\n",
       "        -4.30004150e-01, -3.91895026e-01, -8.83674800e-01,\n",
       "        -9.04183835e-02,  6.16078019e-01, -6.32348359e-02,\n",
       "        -3.85213584e-01,  7.56251335e-01, -1.21315435e-01,\n",
       "        -3.66713285e-01,  2.99512178e-01, -1.09439266e+00,\n",
       "        -4.89820018e-02, -1.22386917e-01,  4.29379046e-02,\n",
       "        -9.31788862e-01,  1.98603943e-01, -5.17829731e-02,\n",
       "        -2.57375091e-01,  3.75362277e-01,  3.55836064e-01,\n",
       "        -6.76045716e-02, -2.33756229e-01, -1.83140755e-01,\n",
       "         3.65882479e-02, -5.80800891e-01,  6.65603057e-02,\n",
       "         3.06537896e-01,  3.39497268e-01,  2.26072803e-01,\n",
       "         1.26469694e-03, -1.65040314e-01, -9.19834375e-02,\n",
       "        -2.16552839e-01,  2.08378792e-01, -1.29969433e-01,\n",
       "         3.84198964e-01,  2.12523788e-01,  2.38466620e-01,\n",
       "         1.81367561e-01, -2.24663675e-01, -2.25000411e-01,\n",
       "        -7.34256878e-02,  5.45266159e-02, -3.08375925e-01,\n",
       "         6.11963451e-01,  3.51845860e-01, -2.39947587e-01,\n",
       "         5.28831258e-02,  1.57497928e-01,  3.44174057e-01,\n",
       "        -6.04678273e-01,  3.74343902e-01,  1.70416027e-01,\n",
       "         3.15806642e-02, -5.41966081e-01, -7.62600422e-01,\n",
       "         1.21697262e-02, -3.11999589e-01,  2.59813368e-01,\n",
       "        -4.41015780e-01, -6.59297034e-03,  6.05921268e-01,\n",
       "        -3.17053378e-01, -1.95380688e-01,  4.29221988e-02,\n",
       "         6.33517504e-01, -1.78063475e-02, -2.34292168e-02,\n",
       "        -3.33128870e-02, -3.69212478e-02, -2.90780813e-01,\n",
       "        -2.16116488e-01,  4.45174053e-02,  3.68889213e-01,\n",
       "        -1.41454950e-01,  2.71184444e-01, -3.56763482e-01,\n",
       "        -1.37216896e-01,  5.87972760e-01,  3.75219584e-02,\n",
       "        -5.38516104e-01,  5.54392338e-01, -3.01773399e-01,\n",
       "        -1.01150286e+00,  3.65679324e-01, -2.25429475e-01,\n",
       "        -2.29305953e-01, -1.75827906e-01,  2.92149503e-02,\n",
       "         4.35879469e-01,  2.71944925e-02, -4.11675870e-01,\n",
       "         2.92072445e-03,  5.43174267e-01, -2.11114481e-01,\n",
       "         2.17932060e-01, -4.09510508e-02, -5.17143831e-02,\n",
       "        -5.05594462e-02,  4.43470664e-02, -2.69019574e-01,\n",
       "         3.08259688e-02, -6.62643462e-04,  2.13742122e-01,\n",
       "        -2.41836067e-02,  8.93224716e-01,  1.29363924e-01,\n",
       "        -3.93588573e-01,  1.43502951e-01,  6.21285997e-02,\n",
       "        -5.65178357e-02, -1.38191104e-01,  2.87676632e-01,\n",
       "        -2.10538045e-01,  6.17667615e-01, -1.25144571e-01,\n",
       "         3.04460451e-02,  2.13158384e-01,  2.33677417e-01,\n",
       "         2.21274480e-01,  5.00445724e-01,  4.38932180e-01,\n",
       "        -1.03884131e-01,  2.70700574e-01, -2.32456237e-01,\n",
       "        -3.22026283e-01, -1.23801716e-01, -5.34731746e-01,\n",
       "         3.02382857e-01,  4.23738956e-02, -2.02068225e-01,\n",
       "        -2.18418211e-01,  1.77502394e-01, -5.71474850e-01,\n",
       "         4.73263822e-02, -3.43319237e-01,  4.07303602e-01,\n",
       "         4.77741271e-01,  1.77272156e-01,  5.36073446e-01,\n",
       "        -9.10163581e-01,  1.18236288e-01,  1.13430042e-02,\n",
       "        -1.23670384e-01, -3.06657590e-02,  3.25731754e-01,\n",
       "        -3.78342927e-01, -5.02465010e-01, -6.78243190e-02,\n",
       "        -1.99354306e-01, -3.91073108e-01,  9.09211338e-02,\n",
       "        -1.17690012e-01,  4.04869765e-01,  9.46513563e-02,\n",
       "         1.44713432e-01, -2.76528299e-01,  1.30882978e-01,\n",
       "        -9.70216393e-02,  2.05251828e-01, -1.26852795e-01,\n",
       "        -1.91952556e-01,  2.37017795e-01, -3.57473284e-01,\n",
       "         1.21851765e-01,  4.15727824e-01,  3.50545570e-02,\n",
       "         1.57633096e-01,  3.93219709e-01,  2.96886712e-02,\n",
       "         3.43798637e-01,  6.39871061e-01,  2.20229521e-01,\n",
       "        -2.41416380e-01,  8.59570026e-01, -3.15636665e-01,\n",
       "         3.40733647e-01, -2.19312221e-01, -7.18547106e-01,\n",
       "         1.84560791e-02,  2.38840163e-01,  5.09695299e-02,\n",
       "        -7.00283945e-02,  3.67007583e-01,  7.67784342e-02,\n",
       "         1.88184902e-01,  3.59740146e-02, -3.06150943e-01,\n",
       "        -1.48867279e-01,  3.31084430e-01, -2.29637995e-01,\n",
       "        -2.68005610e-01, -4.57388818e-01,  2.35615969e-02,\n",
       "        -3.44793051e-01, -1.64295897e-01, -2.79160082e-01,\n",
       "         1.21704839e-01, -9.62834507e-02,  1.78299829e-01,\n",
       "         6.00979567e-01,  1.32331587e-02,  7.01378286e-01,\n",
       "         2.45392635e-01,  4.50738519e-02, -7.28976950e-02,\n",
       "         8.77620280e-02, -3.74237239e-01,  4.14782107e-01,\n",
       "        -2.64577359e-01,  2.72035718e-01, -2.20808268e-01,\n",
       "        -4.12798524e-01, -1.76339909e-01,  1.30267799e-01,\n",
       "         5.15825927e-01, -1.08557403e+00, -1.89582452e-01,\n",
       "        -1.90599948e-01, -6.31913781e-01, -6.63047731e-02,\n",
       "         3.30629826e-01,  2.05184326e-01,  5.91086566e-01,\n",
       "        -5.74519336e-01, -1.74506336e-01, -1.28910869e-01,\n",
       "        -9.05926228e-02,  1.16689969e-03, -7.63665512e-02,\n",
       "         5.24749875e-01,  2.96259075e-01, -1.78702384e-01,\n",
       "         2.21544266e-01, -6.51172936e-01, -7.31461227e-01,\n",
       "         2.71046609e-01, -2.93938994e-01,  7.56695718e-02,\n",
       "        -1.34182572e-01,  1.20113455e-01,  3.42774652e-02,\n",
       "        -4.95359123e-01, -3.65553856e-01,  1.96762845e-01,\n",
       "         5.51533282e-01,  5.18241882e-01,  2.00639427e-01,\n",
       "        -2.23959848e-01,  2.63302296e-01, -4.55830860e+00,\n",
       "         1.36778608e-01, -2.15487182e-01,  9.20735821e-02,\n",
       "        -1.29073173e-01,  1.39421776e-01,  6.70461059e-02,\n",
       "        -1.77671641e-01, -4.84373480e-01, -4.04517174e-01,\n",
       "        -3.21262866e-01, -5.97002059e-02,  3.59575272e-01,\n",
       "         5.99627256e-01, -4.10160452e-01, -4.41991329e-01,\n",
       "         5.21980882e-01,  1.23035803e-01,  8.59283134e-02,\n",
       "         4.38389152e-01,  1.90452322e-01, -2.22277462e-01,\n",
       "        -1.67182893e-01,  1.92756891e-01,  2.78863758e-02,\n",
       "         1.86828792e-01, -3.49157035e-01, -1.87825188e-01,\n",
       "        -1.88942477e-01, -7.89127126e-03,  1.87196374e-01,\n",
       "        -9.27020073e-01, -1.90853998e-02,  7.58184195e-02,\n",
       "         2.26067334e-01,  1.57115653e-01, -2.36178041e-01,\n",
       "         3.28945398e-01, -3.14005613e-01,  3.22809696e-01,\n",
       "         8.24807882e-02, -3.29739064e-01, -5.79928637e-01,\n",
       "         4.09634799e-01,  1.36416042e+00,  9.68975723e-02,\n",
       "         1.93065226e-01,  1.72455490e-01, -1.63402751e-01,\n",
       "        -1.42399818e-01, -9.39576179e-02,  2.23266989e-01,\n",
       "         3.11444044e-01, -1.23570248e-01, -2.31949136e-01,\n",
       "        -1.41660810e-01,  4.78134632e-01,  1.07939325e-01,\n",
       "        -2.97259182e-01, -5.89575350e-01, -3.79075706e-02,\n",
       "        -2.96396583e-01, -7.81477809e-01, -2.62084842e-01,\n",
       "         2.04880118e-01, -1.39717028e-01, -3.53487432e-01,\n",
       "        -1.80997133e-01, -2.37193145e-02, -4.10974920e-01,\n",
       "        -2.94183999e-01,  4.77861464e-01, -4.57721740e-01,\n",
       "        -3.60841662e-01,  5.26287481e-02, -2.74347305e-01,\n",
       "         4.11187321e-01, -3.84184510e-01,  2.94317957e-02,\n",
       "        -2.98852205e-01,  1.23370960e-01, -4.15715724e-01,\n",
       "         1.01210400e-01, -6.57840073e-02, -4.83798027e-01,\n",
       "        -1.44359216e-01,  6.47663102e-02,  7.59405196e-02,\n",
       "        -6.93671942e-01, -2.66680032e-01,  5.17585933e-01,\n",
       "         1.62339881e-01,  4.61656332e-01,  3.26349996e-02,\n",
       "        -3.49026509e-02,  4.74965513e-01,  2.48030543e-01,\n",
       "         2.11850405e-01,  3.62077206e-01, -3.42326999e-01,\n",
       "         1.70523912e-01, -1.67288095e-01,  5.91738522e-01,\n",
       "        -4.63656783e-01, -2.42402285e-01,  2.35181496e-01,\n",
       "        -4.15732294e-01,  5.03219545e-01,  4.67368662e-01,\n",
       "         2.01540425e-01,  1.60584703e-01,  2.05543041e-01,\n",
       "         6.00892246e-01,  1.40558451e-01,  2.21726254e-01,\n",
       "         1.52860776e-01,  2.62316257e-01,  2.36140192e-01,\n",
       "        -6.43343031e-02, -1.50063649e-01, -3.82472515e-01,\n",
       "         1.71754897e-01, -1.75525606e-01,  1.03806727e-01,\n",
       "        -1.79845899e-01, -1.25893578e-03, -5.44909760e-03,\n",
       "         8.79318733e-03, -1.14640638e-01, -2.35104680e-01,\n",
       "        -3.73948514e-01, -2.23150536e-01, -6.64397143e-03,\n",
       "         6.60237312e-01, -1.71667114e-02, -4.19253141e-01,\n",
       "         3.14235419e-01, -3.30324471e-02, -1.57567665e-01,\n",
       "         3.20968151e-01,  2.40535468e-01,  1.35036409e-01,\n",
       "         1.47193685e-01, -4.53291625e-01,  8.12180936e-01,\n",
       "         1.08722612e-01,  3.89684066e-02,  4.53797787e-01,\n",
       "        -5.62689424e-01,  3.39722037e-01, -1.25002563e-01,\n",
       "        -2.19465539e-01, -3.21327239e-01, -2.17874423e-02,\n",
       "         6.06038392e-01,  4.05609488e-01,  3.33886862e-01,\n",
       "        -5.61562702e-02,  2.21744850e-01, -6.89694360e-02,\n",
       "         1.11216441e-01,  4.19812128e-02,  5.45181751e-01,\n",
       "        -1.52331963e-01, -3.37511927e-01,  1.70315146e-01,\n",
       "        -3.48963559e-01,  3.04442555e-01, -1.88030705e-01,\n",
       "         2.39242107e-01, -8.58208686e-02, -3.51463556e-01,\n",
       "         1.58994496e-01, -2.38990679e-01, -1.87369838e-01,\n",
       "         1.61720812e-01, -1.96889490e-01,  2.25910228e-02,\n",
       "         3.57502282e-01,  3.95974338e-01, -8.73240978e-02,\n",
       "         6.89828545e-02, -3.12623948e-01, -1.77909732e-02,\n",
       "         2.13999733e-01,  2.23777592e-02,  2.31715992e-01,\n",
       "        -1.59582287e-01, -4.90004867e-02, -7.85859451e-02,\n",
       "        -6.37004450e-02,  4.73088324e-01,  2.14283600e-01,\n",
       "         9.36800465e-02, -5.67101479e-01, -4.10354048e-01,\n",
       "         4.76966381e-01, -6.83645010e-01, -1.94796875e-01,\n",
       "         6.79288665e-03,  3.40161175e-01,  2.27243215e-01,\n",
       "        -3.63759428e-01,  3.75916272e-01,  2.23770589e-01,\n",
       "        -3.22559237e-01,  4.84812781e-02, -6.64507091e-01,\n",
       "        -4.03163880e-01, -3.71621102e-02, -9.50693429e-01,\n",
       "         1.16414599e-01, -2.15008020e-01,  2.15276405e-01,\n",
       "         7.13908911e-01, -5.25973439e-01, -4.88621369e-02,\n",
       "        -4.86097038e-01, -6.17169797e-01,  2.55562246e-01,\n",
       "         1.30763412e-01, -1.77956030e-01, -3.89162034e-01,\n",
       "        -1.74283072e-01,  2.51666903e-01,  2.15722278e-01,\n",
       "         4.25386250e-01,  2.11614966e-01, -1.92418069e-01,\n",
       "        -3.80954519e-02,  1.28101453e-01, -1.86763728e+00,\n",
       "        -2.47870877e-01,  2.75858164e-01,  3.21796015e-02,\n",
       "         5.43212444e-02, -8.55785757e-02, -5.81243575e-01,\n",
       "         2.01530010e-03, -5.34585834e-01,  6.55299798e-03,\n",
       "         8.00654013e-03, -4.05172616e-01,  4.22953069e-03,\n",
       "         1.41190514e-01,  8.61180425e-02, -2.62031332e-03,\n",
       "         7.25951374e-01, -3.23189348e-01,  6.27629310e-02,\n",
       "        -1.60040423e-01, -4.02269304e-01, -4.14067768e-02,\n",
       "        -2.58968174e-01,  8.89827311e-02,  7.96003789e-02,\n",
       "        -2.95568913e-01, -4.53142166e-01, -4.77286756e-01,\n",
       "        -2.30912432e-01, -2.15468869e-01, -7.56102681e-01,\n",
       "        -2.70214617e-01, -1.22060925e-02, -2.14921981e-01,\n",
       "        -3.37831706e-01,  4.12041321e-03, -2.89659500e-01,\n",
       "         5.56002736e-01, -4.48298872e-01,  2.20669448e-01,\n",
       "        -3.64208430e-01,  1.82315320e-01, -4.51539367e-01,\n",
       "         3.60689014e-02,  3.16982448e-01,  1.21343203e-01,\n",
       "         1.63258716e-01,  7.52108932e-01, -6.05163276e-01,\n",
       "        -2.43136823e-01, -6.58643395e-02, -1.20362751e-01,\n",
       "        -6.61720857e-02,  5.18818319e-01, -1.04872033e-01,\n",
       "         4.73232210e-01,  4.61443603e-01, -4.40887995e-02,\n",
       "        -8.16797435e-01, -2.93974370e-01, -5.64237982e-02,\n",
       "         1.96231663e-01,  1.49169132e-01, -7.20951140e-01,\n",
       "         4.07857329e-01,  6.65917635e-01,  2.30929442e-03,\n",
       "         1.78826563e-02, -2.99976885e-01, -1.38014704e-01,\n",
       "        -8.75144154e-02,  9.26225632e-02,  1.68257505e-01,\n",
       "         5.23945212e-01, -1.20949492e-01,  1.42295286e-01,\n",
       "         3.17807525e-01,  2.27963194e-01, -1.32624745e-01,\n",
       "        -9.34215561e-02, -7.11752623e-02,  7.96653807e-01,\n",
       "         5.39363384e-01, -3.66481930e-01, -1.03916183e-01,\n",
       "        -1.39378086e-01, -1.14611015e-01, -1.16752237e-02,\n",
       "        -1.50848366e-02,  1.43496143e-02, -6.18030801e-02,\n",
       "         1.64865926e-01, -2.10509568e-01,  4.88127351e-01,\n",
       "         1.51064008e-01, -1.46128729e-01,  2.64862210e-01,\n",
       "         2.07645632e-02,  4.28906262e-01, -3.44465449e-02,\n",
       "         3.68332058e-01,  3.37130651e-02,  7.01668039e-02,\n",
       "         6.06981479e-02, -1.45575464e-01, -6.37190193e-02,\n",
       "        -2.53690556e-02,  1.57144547e-01,  3.74373615e-01,\n",
       "         2.93707907e-01,  3.10352117e-01, -6.22842051e-02,\n",
       "         4.11995143e-01, -2.42620319e-01, -3.85062471e-02,\n",
       "        -7.84108415e-02,  2.40882725e-01, -2.02640906e-01,\n",
       "         9.13202167e-02,  1.89240798e-01,  4.03860122e-01,\n",
       "        -5.07210568e-03, -3.33462924e-01,  2.40193844e-01,\n",
       "        -3.53894681e-01,  2.50049114e-01, -3.58512327e-02,\n",
       "         9.10493433e-02,  3.35561484e-01,  3.29842657e-01,\n",
       "         6.35374665e-01,  1.77323028e-01, -3.80117983e-01,\n",
       "         2.16883093e-01,  1.19598314e-01,  9.53047723e-02,\n",
       "        -4.76132572e-01, -3.41616690e-01, -5.36993966e-02,\n",
       "        -7.79976994e-02,  4.63983744e-01, -5.72313070e-01,\n",
       "        -1.81410253e-01,  1.00295857e-01,  1.98272854e-01,\n",
       "         1.28384262e-01,  1.15691818e-01, -1.69387147e-01,\n",
       "         5.86188078e-01, -5.26317470e-02, -5.26439965e-01,\n",
       "        -2.48884454e-01,  1.65503249e-01, -2.03941643e-01,\n",
       "        -3.83307397e-01,  1.86719552e-01,  3.97503823e-01,\n",
       "        -2.88009942e-01,  1.00624599e-02, -1.95815012e-01,\n",
       "        -1.71171993e-01,  4.98232931e-01, -2.81265557e-01,\n",
       "        -2.79379308e-01, -3.49005133e-01,  5.84112048e-01,\n",
       "         2.93036729e-01,  3.40739161e-01,  1.45396575e-01,\n",
       "        -3.44007492e-01, -6.79287553e-01, -5.11810362e-01,\n",
       "         4.18467641e-01,  9.55244452e-02,  5.35855591e-02,\n",
       "         1.09701894e-01, -3.40617001e-01, -2.73603797e-01,\n",
       "         2.79106319e-01, -2.71286041e-01,  1.36818737e-01,\n",
       "        -3.70935470e-01, -6.31214231e-02, -6.06582761e-01,\n",
       "        -1.51357219e-01,  2.43152440e-01,  1.47321403e-01,\n",
       "         7.98868574e-03, -7.49350712e-02, -3.59586328e-01,\n",
       "        -6.05396092e-01,  3.41395587e-01, -3.61143738e-01,\n",
       "         3.48584443e-01, -5.25130868e-01,  4.75848496e-01,\n",
       "         2.84194261e-01,  5.31082414e-02, -2.12647885e-01,\n",
       "        -3.41239870e-01,  1.10487789e-01, -2.69644290e-01,\n",
       "         2.94514537e-01, -1.37637220e-02,  1.39954463e-01,\n",
       "        -2.29768455e-04,  3.81651521e-01, -2.54726946e-01,\n",
       "         1.35358244e-01,  3.84848446e-01,  3.35360587e-01,\n",
       "        -2.60733128e-01,  6.83841631e-02,  7.50525236e-01,\n",
       "        -1.85889781e-01,  1.96066976e-01, -6.58955276e-02,\n",
       "         1.80903375e-01, -1.06627092e-01, -1.58269763e-01,\n",
       "         4.87397313e-01, -1.76172048e-01, -3.37464005e-01,\n",
       "        -1.54993117e-01, -3.88852358e-01, -2.72289962e-01,\n",
       "         3.10074002e-01,  8.82564858e-02, -1.37603402e-01]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_t1_0_embeddings = academic_t1_0.iloc[:, 1:].values\n",
    "academic_t2_0_embeddings = academic_t2_0.iloc[:, 1:].values\n",
    "academic_t1_0_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "edea5b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.0127e-01,  8.2875e-01,  2.9098e-02, -3.5453e-02,  1.7885e-01,\n",
       "          2.1712e-01, -6.6860e-02,  4.1365e-01,  3.1760e-01,  1.8288e-02,\n",
       "         -3.6451e-01,  1.4282e-01,  3.2929e-01,  3.0407e-01,  6.8528e-02,\n",
       "          4.8649e-01,  1.0414e-01, -4.8366e-01,  8.5949e-02, -5.3294e-02,\n",
       "         -1.2735e-01,  2.4094e-01,  4.5931e-01,  6.1490e-01, -1.8857e-02,\n",
       "         -4.0803e-01,  9.4572e-03,  5.5037e-01, -1.0113e-01,  1.8813e-01,\n",
       "          5.5097e-01,  1.3710e-01, -5.5775e-01,  4.6130e-01, -2.8273e-01,\n",
       "          1.2259e-01, -4.6390e-01,  1.9415e-01, -1.3706e-01,  5.1479e-01,\n",
       "         -1.6844e-01, -1.1063e-02, -9.4774e-01,  3.3628e-01, -1.1362e-01,\n",
       "         -1.9258e-01,  7.5871e-02,  8.3207e-01, -2.9018e-01,  6.0798e-01,\n",
       "         -6.6700e-01,  3.1042e-01, -1.5508e-01,  5.7152e-02, -1.9939e-01,\n",
       "          4.3329e-01,  3.9874e-02, -4.3000e-01, -3.9190e-01, -8.8367e-01,\n",
       "         -9.0418e-02,  6.1608e-01, -6.3235e-02, -3.8521e-01,  7.5625e-01,\n",
       "         -1.2132e-01, -3.6671e-01,  2.9951e-01, -1.0944e+00, -4.8982e-02,\n",
       "         -1.2239e-01,  4.2938e-02, -9.3179e-01,  1.9860e-01, -5.1783e-02,\n",
       "         -2.5738e-01,  3.7536e-01,  3.5584e-01, -6.7605e-02, -2.3376e-01,\n",
       "         -1.8314e-01,  3.6588e-02, -5.8080e-01,  6.6560e-02,  3.0654e-01,\n",
       "          3.3950e-01,  2.2607e-01,  1.2647e-03, -1.6504e-01, -9.1983e-02,\n",
       "         -2.1655e-01,  2.0838e-01, -1.2997e-01,  3.8420e-01,  2.1252e-01,\n",
       "          2.3847e-01,  1.8137e-01, -2.2466e-01, -2.2500e-01, -7.3426e-02,\n",
       "          5.4527e-02, -3.0838e-01,  6.1196e-01,  3.5185e-01, -2.3995e-01,\n",
       "          5.2883e-02,  1.5750e-01,  3.4417e-01, -6.0468e-01,  3.7434e-01,\n",
       "          1.7042e-01,  3.1581e-02, -5.4197e-01, -7.6260e-01,  1.2170e-02,\n",
       "         -3.1200e-01,  2.5981e-01, -4.4102e-01, -6.5930e-03,  6.0592e-01,\n",
       "         -3.1705e-01, -1.9538e-01,  4.2922e-02,  6.3352e-01, -1.7806e-02,\n",
       "         -2.3429e-02, -3.3313e-02, -3.6921e-02, -2.9078e-01, -2.1612e-01,\n",
       "          4.4517e-02,  3.6889e-01, -1.4145e-01,  2.7118e-01, -3.5676e-01,\n",
       "         -1.3722e-01,  5.8797e-01,  3.7522e-02, -5.3852e-01,  5.5439e-01,\n",
       "         -3.0177e-01, -1.0115e+00,  3.6568e-01, -2.2543e-01, -2.2931e-01,\n",
       "         -1.7583e-01,  2.9215e-02,  4.3588e-01,  2.7194e-02, -4.1168e-01,\n",
       "          2.9207e-03,  5.4317e-01, -2.1111e-01,  2.1793e-01, -4.0951e-02,\n",
       "         -5.1714e-02, -5.0559e-02,  4.4347e-02, -2.6902e-01,  3.0826e-02,\n",
       "         -6.6264e-04,  2.1374e-01, -2.4184e-02,  8.9322e-01,  1.2936e-01,\n",
       "         -3.9359e-01,  1.4350e-01,  6.2129e-02, -5.6518e-02, -1.3819e-01,\n",
       "          2.8768e-01, -2.1054e-01,  6.1767e-01, -1.2514e-01,  3.0446e-02,\n",
       "          2.1316e-01,  2.3368e-01,  2.2127e-01,  5.0045e-01,  4.3893e-01,\n",
       "         -1.0388e-01,  2.7070e-01, -2.3246e-01, -3.2203e-01, -1.2380e-01,\n",
       "         -5.3473e-01,  3.0238e-01,  4.2374e-02, -2.0207e-01, -2.1842e-01,\n",
       "          1.7750e-01, -5.7147e-01,  4.7326e-02, -3.4332e-01,  4.0730e-01,\n",
       "          4.7774e-01,  1.7727e-01,  5.3607e-01, -9.1016e-01,  1.1824e-01,\n",
       "          1.1343e-02, -1.2367e-01, -3.0666e-02,  3.2573e-01, -3.7834e-01,\n",
       "         -5.0247e-01, -6.7824e-02, -1.9935e-01, -3.9107e-01,  9.0921e-02,\n",
       "         -1.1769e-01,  4.0487e-01,  9.4651e-02,  1.4471e-01, -2.7653e-01,\n",
       "          1.3088e-01, -9.7022e-02,  2.0525e-01, -1.2685e-01, -1.9195e-01,\n",
       "          2.3702e-01, -3.5747e-01,  1.2185e-01,  4.1573e-01,  3.5055e-02,\n",
       "          1.5763e-01,  3.9322e-01,  2.9689e-02,  3.4380e-01,  6.3987e-01,\n",
       "          2.2023e-01, -2.4142e-01,  8.5957e-01, -3.1564e-01,  3.4073e-01,\n",
       "         -2.1931e-01, -7.1855e-01,  1.8456e-02,  2.3884e-01,  5.0970e-02,\n",
       "         -7.0028e-02,  3.6701e-01,  7.6778e-02,  1.8818e-01,  3.5974e-02,\n",
       "         -3.0615e-01, -1.4887e-01,  3.3108e-01, -2.2964e-01, -2.6801e-01,\n",
       "         -4.5739e-01,  2.3562e-02, -3.4479e-01, -1.6430e-01, -2.7916e-01,\n",
       "          1.2170e-01, -9.6283e-02,  1.7830e-01,  6.0098e-01,  1.3233e-02,\n",
       "          7.0138e-01,  2.4539e-01,  4.5074e-02, -7.2898e-02,  8.7762e-02,\n",
       "         -3.7424e-01,  4.1478e-01, -2.6458e-01,  2.7204e-01, -2.2081e-01,\n",
       "         -4.1280e-01, -1.7634e-01,  1.3027e-01,  5.1583e-01, -1.0856e+00,\n",
       "         -1.8958e-01, -1.9060e-01, -6.3191e-01, -6.6305e-02,  3.3063e-01,\n",
       "          2.0518e-01,  5.9109e-01, -5.7452e-01, -1.7451e-01, -1.2891e-01,\n",
       "         -9.0593e-02,  1.1669e-03, -7.6367e-02,  5.2475e-01,  2.9626e-01,\n",
       "         -1.7870e-01,  2.2154e-01, -6.5117e-01, -7.3146e-01,  2.7105e-01,\n",
       "         -2.9394e-01,  7.5670e-02, -1.3418e-01,  1.2011e-01,  3.4277e-02,\n",
       "         -4.9536e-01, -3.6555e-01,  1.9676e-01,  5.5153e-01,  5.1824e-01,\n",
       "          2.0064e-01, -2.2396e-01,  2.6330e-01, -4.5583e+00,  1.3678e-01,\n",
       "         -2.1549e-01,  9.2074e-02, -1.2907e-01,  1.3942e-01,  6.7046e-02,\n",
       "         -1.7767e-01, -4.8437e-01, -4.0452e-01, -3.2126e-01, -5.9700e-02,\n",
       "          3.5958e-01,  5.9963e-01, -4.1016e-01, -4.4199e-01,  5.2198e-01,\n",
       "          1.2304e-01,  8.5928e-02,  4.3839e-01,  1.9045e-01, -2.2228e-01,\n",
       "         -1.6718e-01,  1.9276e-01,  2.7886e-02,  1.8683e-01, -3.4916e-01,\n",
       "         -1.8783e-01, -1.8894e-01, -7.8913e-03,  1.8720e-01, -9.2702e-01,\n",
       "         -1.9085e-02,  7.5818e-02,  2.2607e-01,  1.5712e-01, -2.3618e-01,\n",
       "          3.2895e-01, -3.1401e-01,  3.2281e-01,  8.2481e-02, -3.2974e-01,\n",
       "         -5.7993e-01,  4.0963e-01,  1.3642e+00,  9.6898e-02,  1.9307e-01,\n",
       "          1.7246e-01, -1.6340e-01, -1.4240e-01, -9.3958e-02,  2.2327e-01,\n",
       "          3.1144e-01, -1.2357e-01, -2.3195e-01, -1.4166e-01,  4.7813e-01,\n",
       "          1.0794e-01, -2.9726e-01, -5.8958e-01, -3.7908e-02, -2.9640e-01,\n",
       "         -7.8148e-01, -2.6208e-01,  2.0488e-01, -1.3972e-01, -3.5349e-01,\n",
       "         -1.8100e-01, -2.3719e-02, -4.1097e-01, -2.9418e-01,  4.7786e-01,\n",
       "         -4.5772e-01, -3.6084e-01,  5.2629e-02, -2.7435e-01,  4.1119e-01,\n",
       "         -3.8418e-01,  2.9432e-02, -2.9885e-01,  1.2337e-01, -4.1572e-01,\n",
       "          1.0121e-01, -6.5784e-02, -4.8380e-01, -1.4436e-01,  6.4766e-02,\n",
       "          7.5941e-02, -6.9367e-01, -2.6668e-01,  5.1759e-01,  1.6234e-01,\n",
       "          4.6166e-01,  3.2635e-02, -3.4903e-02,  4.7497e-01,  2.4803e-01,\n",
       "          2.1185e-01,  3.6208e-01, -3.4233e-01,  1.7052e-01, -1.6729e-01,\n",
       "          5.9174e-01, -4.6366e-01, -2.4240e-01,  2.3518e-01, -4.1573e-01,\n",
       "          5.0322e-01,  4.6737e-01,  2.0154e-01,  1.6058e-01,  2.0554e-01,\n",
       "          6.0089e-01,  1.4056e-01,  2.2173e-01,  1.5286e-01,  2.6232e-01,\n",
       "          2.3614e-01, -6.4334e-02, -1.5006e-01, -3.8247e-01,  1.7175e-01,\n",
       "         -1.7553e-01,  1.0381e-01, -1.7985e-01, -1.2589e-03, -5.4491e-03,\n",
       "          8.7932e-03, -1.1464e-01, -2.3510e-01, -3.7395e-01, -2.2315e-01,\n",
       "         -6.6440e-03,  6.6024e-01, -1.7167e-02, -4.1925e-01,  3.1424e-01,\n",
       "         -3.3032e-02, -1.5757e-01,  3.2097e-01,  2.4054e-01,  1.3504e-01,\n",
       "          1.4719e-01, -4.5329e-01,  8.1218e-01,  1.0872e-01,  3.8968e-02,\n",
       "          4.5380e-01, -5.6269e-01,  3.3972e-01, -1.2500e-01, -2.1947e-01,\n",
       "         -3.2133e-01, -2.1787e-02,  6.0604e-01,  4.0561e-01,  3.3389e-01,\n",
       "         -5.6156e-02,  2.2174e-01, -6.8969e-02,  1.1122e-01,  4.1981e-02,\n",
       "          5.4518e-01, -1.5233e-01, -3.3751e-01,  1.7032e-01, -3.4896e-01,\n",
       "          3.0444e-01, -1.8803e-01,  2.3924e-01, -8.5821e-02, -3.5146e-01,\n",
       "          1.5899e-01, -2.3899e-01, -1.8737e-01,  1.6172e-01, -1.9689e-01,\n",
       "          2.2591e-02,  3.5750e-01,  3.9597e-01, -8.7324e-02,  6.8983e-02,\n",
       "         -3.1262e-01, -1.7791e-02,  2.1400e-01,  2.2378e-02,  2.3172e-01,\n",
       "         -1.5958e-01, -4.9000e-02, -7.8586e-02, -6.3700e-02,  4.7309e-01,\n",
       "          2.1428e-01,  9.3680e-02, -5.6710e-01, -4.1035e-01,  4.7697e-01,\n",
       "         -6.8365e-01, -1.9480e-01,  6.7929e-03,  3.4016e-01,  2.2724e-01,\n",
       "         -3.6376e-01,  3.7592e-01,  2.2377e-01, -3.2256e-01,  4.8481e-02,\n",
       "         -6.6451e-01, -4.0316e-01, -3.7162e-02, -9.5069e-01,  1.1641e-01,\n",
       "         -2.1501e-01,  2.1528e-01,  7.1391e-01, -5.2597e-01, -4.8862e-02,\n",
       "         -4.8610e-01, -6.1717e-01,  2.5556e-01,  1.3076e-01, -1.7796e-01,\n",
       "         -3.8916e-01, -1.7428e-01,  2.5167e-01,  2.1572e-01,  4.2539e-01,\n",
       "          2.1161e-01, -1.9242e-01, -3.8095e-02,  1.2810e-01, -1.8676e+00,\n",
       "         -2.4787e-01,  2.7586e-01,  3.2180e-02,  5.4321e-02, -8.5579e-02,\n",
       "         -5.8124e-01,  2.0153e-03, -5.3459e-01,  6.5530e-03,  8.0065e-03,\n",
       "         -4.0517e-01,  4.2295e-03,  1.4119e-01,  8.6118e-02, -2.6203e-03,\n",
       "          7.2595e-01, -3.2319e-01,  6.2763e-02, -1.6004e-01, -4.0227e-01,\n",
       "         -4.1407e-02, -2.5897e-01,  8.8983e-02,  7.9600e-02, -2.9557e-01,\n",
       "         -4.5314e-01, -4.7729e-01, -2.3091e-01, -2.1547e-01, -7.5610e-01,\n",
       "         -2.7021e-01, -1.2206e-02, -2.1492e-01, -3.3783e-01,  4.1204e-03,\n",
       "         -2.8966e-01,  5.5600e-01, -4.4830e-01,  2.2067e-01, -3.6421e-01,\n",
       "          1.8232e-01, -4.5154e-01,  3.6069e-02,  3.1698e-01,  1.2134e-01,\n",
       "          1.6326e-01,  7.5211e-01, -6.0516e-01, -2.4314e-01, -6.5864e-02,\n",
       "         -1.2036e-01, -6.6172e-02,  5.1882e-01, -1.0487e-01,  4.7323e-01,\n",
       "          4.6144e-01, -4.4089e-02, -8.1680e-01, -2.9397e-01, -5.6424e-02,\n",
       "          1.9623e-01,  1.4917e-01, -7.2095e-01,  4.0786e-01,  6.6592e-01,\n",
       "          2.3093e-03,  1.7883e-02, -2.9998e-01, -1.3801e-01, -8.7514e-02,\n",
       "          9.2623e-02,  1.6826e-01,  5.2395e-01, -1.2095e-01,  1.4230e-01,\n",
       "          3.1781e-01,  2.2796e-01, -1.3262e-01, -9.3422e-02, -7.1175e-02,\n",
       "          7.9665e-01,  5.3936e-01, -3.6648e-01, -1.0392e-01, -1.3938e-01,\n",
       "         -1.1461e-01, -1.1675e-02, -1.5085e-02,  1.4350e-02, -6.1803e-02,\n",
       "          1.6487e-01, -2.1051e-01,  4.8813e-01,  1.5106e-01, -1.4613e-01,\n",
       "          2.6486e-01,  2.0765e-02,  4.2891e-01, -3.4447e-02,  3.6833e-01,\n",
       "          3.3713e-02,  7.0167e-02,  6.0698e-02, -1.4558e-01, -6.3719e-02,\n",
       "         -2.5369e-02,  1.5714e-01,  3.7437e-01,  2.9371e-01,  3.1035e-01,\n",
       "         -6.2284e-02,  4.1200e-01, -2.4262e-01, -3.8506e-02, -7.8411e-02,\n",
       "          2.4088e-01, -2.0264e-01,  9.1320e-02,  1.8924e-01,  4.0386e-01,\n",
       "         -5.0721e-03, -3.3346e-01,  2.4019e-01, -3.5389e-01,  2.5005e-01,\n",
       "         -3.5851e-02,  9.1049e-02,  3.3556e-01,  3.2984e-01,  6.3537e-01,\n",
       "          1.7732e-01, -3.8012e-01,  2.1688e-01,  1.1960e-01,  9.5305e-02,\n",
       "         -4.7613e-01, -3.4162e-01, -5.3699e-02, -7.7998e-02,  4.6398e-01,\n",
       "         -5.7231e-01, -1.8141e-01,  1.0030e-01,  1.9827e-01,  1.2838e-01,\n",
       "          1.1569e-01, -1.6939e-01,  5.8619e-01, -5.2632e-02, -5.2644e-01,\n",
       "         -2.4888e-01,  1.6550e-01, -2.0394e-01, -3.8331e-01,  1.8672e-01,\n",
       "          3.9750e-01, -2.8801e-01,  1.0062e-02, -1.9582e-01, -1.7117e-01,\n",
       "          4.9823e-01, -2.8127e-01, -2.7938e-01, -3.4901e-01,  5.8411e-01,\n",
       "          2.9304e-01,  3.4074e-01,  1.4540e-01, -3.4401e-01, -6.7929e-01,\n",
       "         -5.1181e-01,  4.1847e-01,  9.5524e-02,  5.3586e-02,  1.0970e-01,\n",
       "         -3.4062e-01, -2.7360e-01,  2.7911e-01, -2.7129e-01,  1.3682e-01,\n",
       "         -3.7094e-01, -6.3121e-02, -6.0658e-01, -1.5136e-01,  2.4315e-01,\n",
       "          1.4732e-01,  7.9887e-03, -7.4935e-02, -3.5959e-01, -6.0540e-01,\n",
       "          3.4140e-01, -3.6114e-01,  3.4858e-01, -5.2513e-01,  4.7585e-01,\n",
       "          2.8419e-01,  5.3108e-02, -2.1265e-01, -3.4124e-01,  1.1049e-01,\n",
       "         -2.6964e-01,  2.9451e-01, -1.3764e-02,  1.3995e-01, -2.2977e-04,\n",
       "          3.8165e-01, -2.5473e-01,  1.3536e-01,  3.8485e-01,  3.3536e-01,\n",
       "         -2.6073e-01,  6.8384e-02,  7.5053e-01, -1.8589e-01,  1.9607e-01,\n",
       "         -6.5896e-02,  1.8090e-01, -1.0663e-01, -1.5827e-01,  4.8740e-01,\n",
       "         -1.7617e-01, -3.3746e-01, -1.5499e-01, -3.8885e-01, -2.7229e-01,\n",
       "          3.1007e-01,  8.8256e-02, -1.3760e-01]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_t1_0_embeddings = torch.tensor(academic_t1_0_embeddings, dtype=torch.float)\n",
    "academic_t2_0_embeddings = torch.tensor(academic_t2_0_embeddings, dtype=torch.float)\n",
    "academic_t1_0_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24ec12e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'academic_t1_0_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m cos_sim \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcosine_similarity(\u001b[43macademic_t1_0_embeddings\u001b[49m[\u001b[38;5;241m0\u001b[39m], academic_t2_0_embeddings[\u001b[38;5;241m0\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m cos_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m cos_sim\n",
      "\u001b[0;31mNameError\u001b[0m: name 'academic_t1_0_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "cos_sim = F.cosine_similarity(academic_t1_0_embeddings[0], academic_t2_0_embeddings[0], dim=0)\n",
    "cos_dist = 1 - cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3c15e20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7453)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7d36c912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2547)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "77071ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_t1_embeddings = academic_t1.iloc[:, 1:].values\n",
    "academic_t2_embeddings = academic_t2.iloc[:, 1:].values\n",
    "academic_t2_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c164f316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_t1_embeddings = torch.tensor(academic_t1.iloc[:, 1:].values, dtype=torch.float)\n",
    "academic_t2_embeddings = torch.tensor(academic_t2.iloc[:, 1:].values, dtype=torch.float)\n",
    "academic_t2_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5e5e20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = F.cosine_similarity(academic_t1_embeddings, academic_t2_embeddings, dim=1)\n",
    "cos_dist = 1 - cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e9f6506e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8382])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "12e7eb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1618])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6fba920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 31),\n",
       " (7, 31),\n",
       " (12, 31),\n",
       " (11, 31),\n",
       " (12, 31),\n",
       " (9, 31),\n",
       " (18, 31),\n",
       " (2, 31),\n",
       " (13, 31),\n",
       " (6, 31),\n",
       " (0, 31))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert datePublished to datetime and filter documents by year\n",
    "data_fullText['datePublished'] = pd.to_datetime(data_fullText['datePublished'])\n",
    "docs_1950 = data_fullText[data_fullText['datePublished'].dt.year == 1950].copy()\n",
    "docs_1951 = data_fullText[data_fullText['datePublished'].dt.year == 1951].copy()\n",
    "docs_1952 = data_fullText[data_fullText['datePublished'].dt.year == 1952].copy()\n",
    "docs_1953 = data_fullText[data_fullText['datePublished'].dt.year == 1953].copy()\n",
    "docs_1954 = data_fullText[data_fullText['datePublished'].dt.year == 1954].copy()\n",
    "docs_1955 = data_fullText[data_fullText['datePublished'].dt.year == 1955].copy()\n",
    "docs_1956 = data_fullText[data_fullText['datePublished'].dt.year == 1956].copy()\n",
    "docs_1957 = data_fullText[data_fullText['datePublished'].dt.year == 1957].copy()\n",
    "docs_1958 = data_fullText[data_fullText['datePublished'].dt.year == 1958].copy()\n",
    "docs_1959 = data_fullText[data_fullText['datePublished'].dt.year == 1959].copy()\n",
    "docs_1960 = data_fullText[data_fullText['datePublished'].dt.year == 19560].copy()\n",
    "docs_1950.shape, docs_1951.shape, docs_1952.shape, docs_1953.shape, docs_1954.shape, docs_1955.shape, docs_1956.shape, docs_1957.shape, docs_1958.shape, docs_1959.shape, docs_1960.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fb698fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12298, 7491, 12364, 15554, 33962, 38561, 58688, 1543, 6175, 75271)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tedt across two years of data over multiple texts\n",
    "for _ in [docs_1950, docs_1951, docs_1952, docs_1953, docs_1954, docs_1955, docs_1956, docs_1957, docs_1958, docs_1959, docs_1960]:\n",
    "    _['fullText']= _['fullText'].apply(join_strings)\n",
    "\n",
    "len(docs_1950['fullText'].iloc[0]), len(docs_1951['fullText'].iloc[0]), len(docs_1952['fullText'].iloc[0]), len(docs_1953['fullText'].iloc[0]), len(docs_1954['fullText'].iloc[0]), len(docs_1955['fullText'].iloc[0]), len(docs_1956['fullText'].iloc[0]), len(docs_1957['fullText'].iloc[0]), len(docs_1958['fullText'].iloc[0]), len(docs_1959['fullText'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fa6e0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 131, 182, 130, 193, 62, 348, 2, 73, 119, 0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_1950= docs_1950['fullText'].apply(chunk_text_bi).explode().to_list()\n",
    "chunks_1951= docs_1951['fullText'].apply(chunk_text_bi).explode().to_list()\n",
    "chunks_1952= docs_1952['fullText'].apply(chunk_text_bi).explode().to_list()\n",
    "chunks_1953= docs_1953['fullText'].apply(chunk_text_bi).explode().to_list()\n",
    "chunks_1954= docs_1954['fullText'].apply(chunk_text_bi).explode().to_list()\n",
    "chunks_1955= docs_1955['fullText'].apply(chunk_text_bi).explode().to_list()\n",
    "chunks_1956= docs_1956['fullText'].apply(chunk_text_bi).explode().to_list()\n",
    "chunks_1957= docs_1957['fullText'].apply(chunk_text_bi).explode().to_list()\n",
    "chunks_1958= docs_1958['fullText'].apply(chunk_text_bi).explode().to_list()\n",
    "chunks_1959= docs_1959['fullText'].apply(chunk_text_bi).explode().to_list()\n",
    "chunks_1960= docs_1960['fullText'].apply(chunk_text_bi).explode().to_list()\n",
    "len(chunks_1950), len(chunks_1951), len(chunks_1952), len(chunks_1953), len(chunks_1954), len(chunks_1955), len(chunks_1956), len(chunks_1957), len(chunks_1958), len(chunks_1959), len(chunks_1960)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0dc53fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6328     is the modern family better or worse than the ...\n",
       "6328     in a very real sense, the traditional family a...\n",
       "6328     individualistic marriage clearly places pleasu...\n",
       "6328     dreams of youth the romantic conception of mar...\n",
       "6328     if not equal rights, in courtship, at least ra...\n",
       "                               ...                        \n",
       "16866    birthday, august 31, 1881, a beautiful edition...\n",
       "16866    on he intends to study very hard. a pleasant b...\n",
       "16866    visited his cousin jessie bones, he found out ...\n",
       "16866    woodrow's right. on wednes day, the following ...\n",
       "16866    that they are both gone, it seems strange that...\n",
       "Name: fullText, Length: 61, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_chunks = [chunks_1950, chunks_1951, chunks_1952, chunks_1953, chunks_1954, chunks_1955, chunks_1956, chunks_1957, chunks_1958, chunks_1959, chunks_1960]\n",
    "docs_1950['fullText'].apply(chunk_text_bi).explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3f63cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processed chunks: 2416 \n",
      "✔ Processed chunks: 2419 \n",
      "✔ Processed chunks: 2511 \n",
      "✔ Processed chunks: 2578 \n",
      "✔ Processed chunks: 2188 \n",
      "✔ Processed chunks: 2526 \n",
      "✔ Processed chunks: 2589 \n",
      "✔ Processed chunks: 2434 \n",
      "✔ Processed chunks: 2499 \n",
      "✔ Processed chunks: 2566 \n",
      "✔ Processed chunks: 2745 \n",
      "✔ Processed chunks: 2476 \n",
      "✔ Processed chunks: 2479 \n",
      "✔ Processed chunks: 1768 \n",
      "✔ Processed chunks: 2485 \n",
      "✔ Processed chunks: 2463 \n",
      "✔ Processed chunks: 2508 \n",
      "✔ Processed chunks: 2460 \n",
      "✔ Processed chunks: 2432 \n",
      "✔ Processed chunks: 2320 \n",
      "✔ Processed chunks: 1956 \n",
      "✔ Processed chunks: 2356 \n",
      "✔ Processed chunks: 2446 \n",
      "✔ Processed chunks: 2312 \n",
      "✔ Processed chunks: 2480 \n",
      "✔ Processed chunks: 2468 \n",
      "✔ Processed chunks: 2501 \n",
      "✔ Processed chunks: 2491 \n",
      "✔ Processed chunks: 2489 \n",
      "✔ Processed chunks: 2592 \n",
      "✔ Processed chunks: 2277 \n",
      "✔ Processed chunks: 574 \n",
      "✔ Processed chunks: 1742 \n",
      "✔ Processed chunks: 2487 \n",
      "✔ Processed chunks: 2200 \n",
      "✔ Processed chunks: 1996 \n",
      "✔ Processed chunks: 2071 \n",
      "✔ Processed chunks: 2856 \n",
      "✔ Processed chunks: 2981 \n",
      "✔ Processed chunks: 2769 \n",
      "✔ Processed chunks: 2782 \n",
      "✔ Processed chunks: 2770 \n",
      "✔ Processed chunks: 2893 \n",
      "✔ Processed chunks: 2787 \n",
      "✔ Processed chunks: 2749 \n",
      "✔ Processed chunks: 2702 \n",
      "✔ Processed chunks: 2202 \n",
      "✔ Processed chunks: 2467 \n",
      "✔ Processed chunks: 2303 \n",
      "✔ Processed chunks: 2366 \n",
      "✔ Processed chunks: 2444 \n",
      "✔ Processed chunks: 2413 \n",
      "✔ Processed chunks: 2245 \n",
      "✔ Processed chunks: 2442 \n",
      "✔ Processed chunks: 2337 \n",
      "✔ Processed chunks: 2367 \n",
      "✔ Processed chunks: 2353 \n",
      "✔ Processed chunks: 2372 \n",
      "✔ Processed chunks: 2372 \n",
      "✔ Processed chunks: 2500 \n",
      "✔ Processed chunks: 160 \n",
      "✔ Processed chunks: 2348 \n",
      "✔ Processed chunks: 2385 \n",
      "✔ Processed chunks: 2329 \n",
      "✔ Processed chunks: 213 \n",
      "✔ Processed chunks: 2256 \n",
      "✔ Processed chunks: 2513 \n",
      "✔ Processed chunks: 2480 \n",
      "✔ Processed chunks: 2605 \n",
      "✔ Processed chunks: 2635 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m df_timestamp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[0;32m----> 5\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43membTokenDf_bi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     df_timestamp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_timestamp, df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m list_timestamps\u001b[38;5;241m.\u001b[39mappend(df_timestamp)\n",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m, in \u001b[0;36membTokenDf_bi\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m      9\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m encoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 12\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Shape: [1, seq_len, hidden_size]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# -> [seq_len, hidden_size]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:811\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    809\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(input_shape, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# (bs, seq_length)\u001b[39;00m\n\u001b[0;32m--> 811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:572\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    564\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    565\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    566\u001b[0m         hidden_state,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m         output_attentions,\n\u001b[1;32m    570\u001b[0m     )\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 572\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:498\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    507\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:223\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"group heads\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bs, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads \u001b[38;5;241m*\u001b[39m dim_per_head)\n\u001b[0;32m--> 223\u001b[0m q \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_lin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    224\u001b[0m k \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_lin(key))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    225\u001b[0m v \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_lin(value))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ada_dho/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_timestamps = []\n",
    "for chunks in list_of_chunks:\n",
    "    df_timestamp = pd.DataFrame()\n",
    "    for chunk in chunks:\n",
    "        df = embTokenDf_bi(chunk)\n",
    "        df_timestamp = pd.concat([df_timestamp, df], ignore_index=True)\n",
    "    list_timestamps.append(df_timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "be22a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outputs = pd.DataFrame()\n",
    "for _ in list_timestamps:\n",
    "    df_outputs = pd.concat([df_outputs, _], ignore_index=True)\n",
    "df_outputs.to_csv(path + '/1950-60_timestamps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27b696a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 42 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 334 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 99 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 167 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 210 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 182 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 512 tokens\n",
      "✔ Processed chunk with 52 tokens\n"
     ]
    }
   ],
   "source": [
    "df_1951 = pd.DataFrame()\n",
    "for chunk in chunks_1951:\n",
    "    df = embTokenDf_bi(chunk)\n",
    "    df_1951 = pd.concat([df_1951, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ae895acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(list_timestamps)):\n",
    "   list_timestamps[i] = average_token_embeddings(list_timestamps[i])\n",
    "\n",
    "#df_avg_1960s = average_token_embeddings(df_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9fbcb08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>-0.173564</td>\n",
       "      <td>-0.001415</td>\n",
       "      <td>-0.372517</td>\n",
       "      <td>0.013558</td>\n",
       "      <td>-0.007874</td>\n",
       "      <td>0.166111</td>\n",
       "      <td>0.273462</td>\n",
       "      <td>0.264120</td>\n",
       "      <td>-0.121148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109196</td>\n",
       "      <td>-0.098556</td>\n",
       "      <td>-0.192099</td>\n",
       "      <td>-0.221098</td>\n",
       "      <td>-0.043698</td>\n",
       "      <td>-0.231565</td>\n",
       "      <td>-0.068316</td>\n",
       "      <td>-0.125227</td>\n",
       "      <td>0.456746</td>\n",
       "      <td>0.381557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>-0.644066</td>\n",
       "      <td>-0.195079</td>\n",
       "      <td>-0.312870</td>\n",
       "      <td>-0.215297</td>\n",
       "      <td>0.591092</td>\n",
       "      <td>0.511108</td>\n",
       "      <td>0.166220</td>\n",
       "      <td>0.777386</td>\n",
       "      <td>0.244445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146638</td>\n",
       "      <td>-0.129626</td>\n",
       "      <td>0.440549</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>-0.387833</td>\n",
       "      <td>-0.536051</td>\n",
       "      <td>0.231392</td>\n",
       "      <td>-0.166077</td>\n",
       "      <td>0.424453</td>\n",
       "      <td>0.580969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>-0.872634</td>\n",
       "      <td>-0.198744</td>\n",
       "      <td>-0.352505</td>\n",
       "      <td>0.139343</td>\n",
       "      <td>0.772203</td>\n",
       "      <td>0.387377</td>\n",
       "      <td>-0.039653</td>\n",
       "      <td>0.627828</td>\n",
       "      <td>-0.123809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321611</td>\n",
       "      <td>-0.181131</td>\n",
       "      <td>0.509595</td>\n",
       "      <td>-0.253463</td>\n",
       "      <td>-0.417379</td>\n",
       "      <td>-0.440532</td>\n",
       "      <td>-0.002649</td>\n",
       "      <td>-0.118817</td>\n",
       "      <td>0.638899</td>\n",
       "      <td>0.190504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modern</td>\n",
       "      <td>-0.362795</td>\n",
       "      <td>0.399894</td>\n",
       "      <td>0.118737</td>\n",
       "      <td>-0.055235</td>\n",
       "      <td>0.532457</td>\n",
       "      <td>0.242924</td>\n",
       "      <td>0.395029</td>\n",
       "      <td>0.372157</td>\n",
       "      <td>0.361836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240094</td>\n",
       "      <td>0.139778</td>\n",
       "      <td>0.125435</td>\n",
       "      <td>0.061648</td>\n",
       "      <td>-0.054641</td>\n",
       "      <td>-0.524150</td>\n",
       "      <td>0.036026</td>\n",
       "      <td>-0.444385</td>\n",
       "      <td>0.519009</td>\n",
       "      <td>-0.289817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>family</td>\n",
       "      <td>0.075545</td>\n",
       "      <td>-0.043301</td>\n",
       "      <td>-0.079803</td>\n",
       "      <td>-0.151824</td>\n",
       "      <td>0.534386</td>\n",
       "      <td>0.529072</td>\n",
       "      <td>-0.217864</td>\n",
       "      <td>0.534916</td>\n",
       "      <td>-0.085863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042748</td>\n",
       "      <td>0.376820</td>\n",
       "      <td>0.226948</td>\n",
       "      <td>0.071193</td>\n",
       "      <td>-0.218720</td>\n",
       "      <td>-0.648808</td>\n",
       "      <td>-0.048910</td>\n",
       "      <td>-0.385934</td>\n",
       "      <td>0.384932</td>\n",
       "      <td>0.843782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29668</th>\n",
       "      <td>##ck</td>\n",
       "      <td>0.688486</td>\n",
       "      <td>-0.592037</td>\n",
       "      <td>0.496471</td>\n",
       "      <td>-0.034212</td>\n",
       "      <td>0.796607</td>\n",
       "      <td>-0.572064</td>\n",
       "      <td>-0.655544</td>\n",
       "      <td>0.331203</td>\n",
       "      <td>-0.589233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.722268</td>\n",
       "      <td>0.144166</td>\n",
       "      <td>-0.235767</td>\n",
       "      <td>-0.152256</td>\n",
       "      <td>-0.127250</td>\n",
       "      <td>-0.147607</td>\n",
       "      <td>-0.002248</td>\n",
       "      <td>0.419696</td>\n",
       "      <td>0.138022</td>\n",
       "      <td>-0.351964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29669</th>\n",
       "      <td>##well</td>\n",
       "      <td>0.015081</td>\n",
       "      <td>0.014210</td>\n",
       "      <td>-0.075487</td>\n",
       "      <td>0.077901</td>\n",
       "      <td>1.423095</td>\n",
       "      <td>-0.585292</td>\n",
       "      <td>0.291550</td>\n",
       "      <td>-0.098561</td>\n",
       "      <td>-0.706675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275498</td>\n",
       "      <td>0.252352</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>-0.333276</td>\n",
       "      <td>-0.060797</td>\n",
       "      <td>-0.178862</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.426722</td>\n",
       "      <td>0.257472</td>\n",
       "      <td>0.025212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29670</th>\n",
       "      <td>.</td>\n",
       "      <td>0.552413</td>\n",
       "      <td>0.279539</td>\n",
       "      <td>-0.078054</td>\n",
       "      <td>0.680449</td>\n",
       "      <td>-0.098909</td>\n",
       "      <td>-1.071219</td>\n",
       "      <td>0.276649</td>\n",
       "      <td>-0.493670</td>\n",
       "      <td>0.495562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>-0.148623</td>\n",
       "      <td>-0.386481</td>\n",
       "      <td>-0.941105</td>\n",
       "      <td>0.046665</td>\n",
       "      <td>-0.745963</td>\n",
       "      <td>-0.007025</td>\n",
       "      <td>0.283435</td>\n",
       "      <td>-0.320415</td>\n",
       "      <td>-0.373267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>18</td>\n",
       "      <td>0.186785</td>\n",
       "      <td>0.524984</td>\n",
       "      <td>0.301117</td>\n",
       "      <td>-0.216900</td>\n",
       "      <td>0.496778</td>\n",
       "      <td>-0.223749</td>\n",
       "      <td>0.377785</td>\n",
       "      <td>0.253711</td>\n",
       "      <td>0.334212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139591</td>\n",
       "      <td>-0.169073</td>\n",
       "      <td>-0.781200</td>\n",
       "      <td>-0.332485</td>\n",
       "      <td>-0.370817</td>\n",
       "      <td>-0.550152</td>\n",
       "      <td>0.304882</td>\n",
       "      <td>0.275885</td>\n",
       "      <td>-0.219865</td>\n",
       "      <td>0.111313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>0.549972</td>\n",
       "      <td>0.430809</td>\n",
       "      <td>-0.008919</td>\n",
       "      <td>0.334195</td>\n",
       "      <td>-0.108196</td>\n",
       "      <td>-1.121435</td>\n",
       "      <td>0.394596</td>\n",
       "      <td>-0.441729</td>\n",
       "      <td>0.113962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069120</td>\n",
       "      <td>-0.061446</td>\n",
       "      <td>-0.289174</td>\n",
       "      <td>-0.807428</td>\n",
       "      <td>0.025060</td>\n",
       "      <td>-0.619435</td>\n",
       "      <td>-0.143617</td>\n",
       "      <td>0.309373</td>\n",
       "      <td>-0.455026</td>\n",
       "      <td>-0.242528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29673 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        token         0         1         2         3         4         5  \\\n",
       "0       [CLS] -0.173564 -0.001415 -0.372517  0.013558 -0.007874  0.166111   \n",
       "1          is -0.644066 -0.195079 -0.312870 -0.215297  0.591092  0.511108   \n",
       "2         the -0.872634 -0.198744 -0.352505  0.139343  0.772203  0.387377   \n",
       "3      modern -0.362795  0.399894  0.118737 -0.055235  0.532457  0.242924   \n",
       "4      family  0.075545 -0.043301 -0.079803 -0.151824  0.534386  0.529072   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "29668    ##ck  0.688486 -0.592037  0.496471 -0.034212  0.796607 -0.572064   \n",
       "29669  ##well  0.015081  0.014210 -0.075487  0.077901  1.423095 -0.585292   \n",
       "29670       .  0.552413  0.279539 -0.078054  0.680449 -0.098909 -1.071219   \n",
       "29671      18  0.186785  0.524984  0.301117 -0.216900  0.496778 -0.223749   \n",
       "29672   [SEP]  0.549972  0.430809 -0.008919  0.334195 -0.108196 -1.121435   \n",
       "\n",
       "              6         7         8  ...       758       759       760  \\\n",
       "0      0.273462  0.264120 -0.121148  ...  0.109196 -0.098556 -0.192099   \n",
       "1      0.166220  0.777386  0.244445  ...  0.146638 -0.129626  0.440549   \n",
       "2     -0.039653  0.627828 -0.123809  ...  0.321611 -0.181131  0.509595   \n",
       "3      0.395029  0.372157  0.361836  ...  0.240094  0.139778  0.125435   \n",
       "4     -0.217864  0.534916 -0.085863  ...  0.042748  0.376820  0.226948   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "29668 -0.655544  0.331203 -0.589233  ... -0.722268  0.144166 -0.235767   \n",
       "29669  0.291550 -0.098561 -0.706675  ... -0.275498  0.252352  0.012241   \n",
       "29670  0.276649 -0.493670  0.495562  ...  0.000788 -0.148623 -0.386481   \n",
       "29671  0.377785  0.253711  0.334212  ...  0.139591 -0.169073 -0.781200   \n",
       "29672  0.394596 -0.441729  0.113962  ... -0.069120 -0.061446 -0.289174   \n",
       "\n",
       "            761       762       763       764       765       766       767  \n",
       "0     -0.221098 -0.043698 -0.231565 -0.068316 -0.125227  0.456746  0.381557  \n",
       "1      0.004702 -0.387833 -0.536051  0.231392 -0.166077  0.424453  0.580969  \n",
       "2     -0.253463 -0.417379 -0.440532 -0.002649 -0.118817  0.638899  0.190504  \n",
       "3      0.061648 -0.054641 -0.524150  0.036026 -0.444385  0.519009 -0.289817  \n",
       "4      0.071193 -0.218720 -0.648808 -0.048910 -0.385934  0.384932  0.843782  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "29668 -0.152256 -0.127250 -0.147607 -0.002248  0.419696  0.138022 -0.351964  \n",
       "29669 -0.333276 -0.060797 -0.178862  0.008941  0.426722  0.257472  0.025212  \n",
       "29670 -0.941105  0.046665 -0.745963 -0.007025  0.283435 -0.320415 -0.373267  \n",
       "29671 -0.332485 -0.370817 -0.550152  0.304882  0.275885 -0.219865  0.111313  \n",
       "29672 -0.807428  0.025060 -0.619435 -0.143617  0.309373 -0.455026 -0.242528  \n",
       "\n",
       "[29673 rows x 769 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_timestamps[0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c5608aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keeping',\n",
       " '99',\n",
       " 'feared',\n",
       " 'forty',\n",
       " 'marked',\n",
       " 'en',\n",
       " 'accomplished',\n",
       " 'comprise',\n",
       " '<',\n",
       " '##es',\n",
       " 'instructional',\n",
       " '##rac',\n",
       " '14',\n",
       " 'delivered',\n",
       " 'instead',\n",
       " 'beloved',\n",
       " 'listen',\n",
       " 'mistake',\n",
       " 'qu',\n",
       " '##sed',\n",
       " 'row',\n",
       " 'meat',\n",
       " 'maximum',\n",
       " 'techniques',\n",
       " 'features',\n",
       " 'decades',\n",
       " 'economy',\n",
       " 'treat',\n",
       " 'liberty',\n",
       " 'drawing',\n",
       " 'gradually',\n",
       " 'wonder',\n",
       " '##pt',\n",
       " 'maintenance',\n",
       " 'buy',\n",
       " 'rome',\n",
       " 'eye',\n",
       " 'philosophy',\n",
       " 'cake',\n",
       " 'develop',\n",
       " 'walter',\n",
       " '26',\n",
       " 'newspapers',\n",
       " 'spoken',\n",
       " 'film',\n",
       " '##side',\n",
       " 'mum',\n",
       " '##rich',\n",
       " 'hopeful',\n",
       " 'rejected',\n",
       " 'respectful',\n",
       " 'labor',\n",
       " 'vision',\n",
       " 'grants',\n",
       " 'authentic',\n",
       " 'it',\n",
       " 'chords',\n",
       " 'graves',\n",
       " '##rem',\n",
       " 'factual',\n",
       " 'migrate',\n",
       " '194',\n",
       " 'describing',\n",
       " 'photographers',\n",
       " 'le',\n",
       " 'russia',\n",
       " 'reader',\n",
       " 'daniel',\n",
       " 'seem',\n",
       " 'critics',\n",
       " 'popular',\n",
       " 'true',\n",
       " 'discussing',\n",
       " 'reply',\n",
       " 'bitter',\n",
       " 'beside',\n",
       " 'reactions',\n",
       " 'pre',\n",
       " '##par',\n",
       " 'et',\n",
       " 'films',\n",
       " 'furnished',\n",
       " 'sw',\n",
       " 'accept',\n",
       " '##hat',\n",
       " 'savings',\n",
       " 'afternoons',\n",
       " 'borrowed',\n",
       " 'timber',\n",
       " 'pushed',\n",
       " 'succession',\n",
       " 'revisions',\n",
       " 'adds',\n",
       " 'department',\n",
       " '##lt',\n",
       " 'ne',\n",
       " 'thinking',\n",
       " 'ate',\n",
       " 'jefferson',\n",
       " 'staff',\n",
       " 'perception',\n",
       " '##mity',\n",
       " 'farmer',\n",
       " 'un',\n",
       " 'tourists',\n",
       " 'falling',\n",
       " 'survive',\n",
       " 'vary',\n",
       " 'bucket',\n",
       " 'whatever',\n",
       " 'female',\n",
       " 'pan',\n",
       " 'freely',\n",
       " 'bonnet',\n",
       " 'mount',\n",
       " 'world',\n",
       " 'leg',\n",
       " 'tun',\n",
       " 'separately',\n",
       " 'holiday',\n",
       " 'still',\n",
       " 'does',\n",
       " 'search',\n",
       " 'approach',\n",
       " 'deliberate',\n",
       " 'exceptions',\n",
       " 'parts',\n",
       " 'speaking',\n",
       " '1917',\n",
       " 'honor',\n",
       " 'developed',\n",
       " 'tori',\n",
       " 'exact',\n",
       " 'ornamental',\n",
       " 'oh',\n",
       " 'lowering',\n",
       " 'exists',\n",
       " 'motor',\n",
       " 'ind',\n",
       " 'formal',\n",
       " 'joined',\n",
       " 'truth',\n",
       " 'distribute',\n",
       " 'banks',\n",
       " 'slight',\n",
       " 'adverse',\n",
       " 'my',\n",
       " 'feels',\n",
       " 'later',\n",
       " '4',\n",
       " '##uation',\n",
       " 'brothers',\n",
       " '##dina',\n",
       " 'improving',\n",
       " 'channel',\n",
       " 'south',\n",
       " '##ess',\n",
       " '##vers',\n",
       " 'becomes',\n",
       " '##por',\n",
       " 'never',\n",
       " 'audiences',\n",
       " 'begging',\n",
       " 'exploit',\n",
       " 'nerves',\n",
       " '##vie',\n",
       " 'waste',\n",
       " 'formerly',\n",
       " 'daughters',\n",
       " '1949',\n",
       " 'socialism',\n",
       " 'jointly',\n",
       " '##iv',\n",
       " 'causes',\n",
       " '##rre',\n",
       " '21',\n",
       " 'pub',\n",
       " 'ae',\n",
       " 'bell',\n",
       " 'slip',\n",
       " 'visit',\n",
       " 'participate',\n",
       " '##icated',\n",
       " 'act',\n",
       " 'human',\n",
       " 'ones',\n",
       " 'slowly',\n",
       " 'else',\n",
       " 'rings',\n",
       " '##mounted',\n",
       " 'uncle',\n",
       " '##rel',\n",
       " 'adult',\n",
       " '##ional',\n",
       " '1932',\n",
       " 'so',\n",
       " 'sickness',\n",
       " 'quick',\n",
       " 'son',\n",
       " 'handicap',\n",
       " 'neutrality',\n",
       " '##re',\n",
       " 'affected',\n",
       " '##ies',\n",
       " 'job',\n",
       " 'immediately',\n",
       " 'likes',\n",
       " 'ordinary',\n",
       " 'admits',\n",
       " 'geographic',\n",
       " 'pictures',\n",
       " 'consumption',\n",
       " 'main',\n",
       " '##sum',\n",
       " 'gone',\n",
       " 'ring',\n",
       " 'sabbath',\n",
       " 'assume',\n",
       " 'subjected',\n",
       " 'hess',\n",
       " 'pick',\n",
       " '##sb',\n",
       " 'georgia',\n",
       " 'analyze',\n",
       " '##nable',\n",
       " '700',\n",
       " 'hebrew',\n",
       " 'under',\n",
       " '333',\n",
       " '##stock',\n",
       " 'warehouses',\n",
       " 'loved',\n",
       " 'tool',\n",
       " 'art',\n",
       " 'musical',\n",
       " 'whole',\n",
       " 'sanctioned',\n",
       " 'household',\n",
       " '1920',\n",
       " '##con',\n",
       " '##body',\n",
       " 'gerard',\n",
       " 'landlord',\n",
       " 'maurice',\n",
       " 'leader',\n",
       " '##tions',\n",
       " 'only',\n",
       " 'swamp',\n",
       " 'directly',\n",
       " 'person',\n",
       " 'phases',\n",
       " 'exercise',\n",
       " 'customers',\n",
       " 'that',\n",
       " 'talked',\n",
       " 'patriarch',\n",
       " 'supplement',\n",
       " 'surprise',\n",
       " 'speeches',\n",
       " '##vo',\n",
       " '##ava',\n",
       " 'coming',\n",
       " 'adapt',\n",
       " 'best',\n",
       " '##quent',\n",
       " 'anxiety',\n",
       " 'witnessed',\n",
       " 'view',\n",
       " 'helped',\n",
       " 'categories',\n",
       " 'step',\n",
       " '66',\n",
       " 'ga',\n",
       " 'constitute',\n",
       " 'submission',\n",
       " 'away',\n",
       " 'der',\n",
       " 'fox',\n",
       " 'recognize',\n",
       " 'averaging',\n",
       " 'selecting',\n",
       " 'helen',\n",
       " 'character',\n",
       " 'graphs',\n",
       " 'operative',\n",
       " 'launched',\n",
       " '##cts',\n",
       " 'self',\n",
       " '38',\n",
       " 'markets',\n",
       " 'projects',\n",
       " '##oc',\n",
       " 'comprising',\n",
       " 'brief',\n",
       " 'usual',\n",
       " 'steady',\n",
       " 'picnic',\n",
       " '##pro',\n",
       " 'account',\n",
       " 'date',\n",
       " 'illustrations',\n",
       " 'sen',\n",
       " '##fire',\n",
       " 'prostitution',\n",
       " 'passed',\n",
       " '##edes',\n",
       " '##air',\n",
       " 'leaders',\n",
       " 'post',\n",
       " 'tiny',\n",
       " 'speaks',\n",
       " 'wear',\n",
       " 'exceptional',\n",
       " 'then',\n",
       " 'rooms',\n",
       " 'germany',\n",
       " 'immediate',\n",
       " 'habit',\n",
       " 'lacked',\n",
       " 'kept',\n",
       " 'resentment',\n",
       " 'weeks',\n",
       " 'residual',\n",
       " 'i',\n",
       " 'suit',\n",
       " 'gift',\n",
       " 'brace',\n",
       " 'fought',\n",
       " '##ifies',\n",
       " 'convenient',\n",
       " '11',\n",
       " 'tickets',\n",
       " 'represented',\n",
       " 'another',\n",
       " '25',\n",
       " 'other',\n",
       " '##ab',\n",
       " 'house',\n",
       " 'locating',\n",
       " 'sub',\n",
       " 'limit',\n",
       " 'loving',\n",
       " 'market',\n",
       " 'closing',\n",
       " 'replied',\n",
       " 'blur',\n",
       " 'retired',\n",
       " '##istle',\n",
       " '##unce',\n",
       " 'forward',\n",
       " 'enough',\n",
       " 'id',\n",
       " 'statements',\n",
       " 'meant',\n",
       " 'posters',\n",
       " '##do',\n",
       " '##cing',\n",
       " 'devices',\n",
       " 'noteworthy',\n",
       " 'admired',\n",
       " 'parental',\n",
       " 'concentrate',\n",
       " 'hall',\n",
       " 'cr',\n",
       " 'maintained',\n",
       " 'central',\n",
       " 'independent',\n",
       " 'animals',\n",
       " 'live',\n",
       " 'articles',\n",
       " '##ot',\n",
       " 'allied',\n",
       " 'aluminum',\n",
       " 'agreements',\n",
       " 'responsible',\n",
       " 'favors',\n",
       " '##ds',\n",
       " 'fiction',\n",
       " 'combinations',\n",
       " 'lowered',\n",
       " '31',\n",
       " 'province',\n",
       " '>',\n",
       " 'low',\n",
       " 'many',\n",
       " 'loss',\n",
       " 'instructors',\n",
       " 'removed',\n",
       " 'like',\n",
       " 'dominated',\n",
       " 'featured',\n",
       " 'branches',\n",
       " 'numbers',\n",
       " 'mortgage',\n",
       " 'stand',\n",
       " '##pose',\n",
       " '##org',\n",
       " '##ance',\n",
       " '##bility',\n",
       " 'carry',\n",
       " 'accompanied',\n",
       " 'closely',\n",
       " 'henry',\n",
       " 'country',\n",
       " 'water',\n",
       " '##oke',\n",
       " 'formidable',\n",
       " 'ou',\n",
       " '##ent',\n",
       " 'smaller',\n",
       " 'receipts',\n",
       " 'head',\n",
       " 'satin',\n",
       " 'isabella',\n",
       " 'rains',\n",
       " 'sitting',\n",
       " 'byte',\n",
       " 'r',\n",
       " 'pathetic',\n",
       " 'talk',\n",
       " 'ville',\n",
       " '326',\n",
       " 'delightful',\n",
       " 'happened',\n",
       " 'feast',\n",
       " 'lot',\n",
       " 'aside',\n",
       " 'welfare',\n",
       " 'alternatives',\n",
       " '1946',\n",
       " 'extraordinary',\n",
       " 'tan',\n",
       " 'al',\n",
       " 'purchase',\n",
       " 'administrative',\n",
       " 'portugal',\n",
       " 'grown',\n",
       " 'subjects',\n",
       " 'save',\n",
       " '##ity',\n",
       " '##lusion',\n",
       " 'these',\n",
       " 'telling',\n",
       " 'assure',\n",
       " 'selective',\n",
       " 'egg',\n",
       " 'core',\n",
       " 'pen',\n",
       " \"'\",\n",
       " 'reports',\n",
       " 'economies',\n",
       " '(',\n",
       " 'mer',\n",
       " 'prints',\n",
       " 'aus',\n",
       " '##ving',\n",
       " 'em',\n",
       " 'turnover',\n",
       " 'key',\n",
       " 'louise',\n",
       " 'multi',\n",
       " 'traditional',\n",
       " 'quietly',\n",
       " 'cover',\n",
       " 'explains',\n",
       " '##2',\n",
       " 'hand',\n",
       " 'income',\n",
       " 'exhausted',\n",
       " 'weekly',\n",
       " 'patronage',\n",
       " 'likewise',\n",
       " 'newly',\n",
       " '186',\n",
       " 'safe',\n",
       " 'chill',\n",
       " 'planned',\n",
       " 'debates',\n",
       " '##ism',\n",
       " 'migration',\n",
       " '##itating',\n",
       " 'au',\n",
       " 'forget',\n",
       " 'imposed',\n",
       " '##ura',\n",
       " '##ta',\n",
       " 'cross',\n",
       " 'institut',\n",
       " 'ave',\n",
       " 'includes',\n",
       " '##alo',\n",
       " 'overnight',\n",
       " 'liquid',\n",
       " 'bind',\n",
       " 'romantic',\n",
       " 'investment',\n",
       " '[SEP]',\n",
       " 'era',\n",
       " 'woodrow',\n",
       " '##phi',\n",
       " 'prevented',\n",
       " 'got',\n",
       " 'capacity',\n",
       " 'economics',\n",
       " 'funds',\n",
       " 'oral',\n",
       " 'eugene',\n",
       " 'rules',\n",
       " 'planning',\n",
       " 'took',\n",
       " '##dic',\n",
       " 'showed',\n",
       " '##ant',\n",
       " 'mother',\n",
       " 'equal',\n",
       " 'with',\n",
       " '##ness',\n",
       " 'august',\n",
       " '##sten',\n",
       " 'present',\n",
       " '23',\n",
       " 'description',\n",
       " 'vance',\n",
       " '##zation',\n",
       " 'dance',\n",
       " 'rule',\n",
       " '151',\n",
       " 'considerable',\n",
       " 'crown',\n",
       " '##ened',\n",
       " 'fine',\n",
       " 'found',\n",
       " 'either',\n",
       " '##graph',\n",
       " '98',\n",
       " 'graduate',\n",
       " 'modified',\n",
       " 'blue',\n",
       " 'bored',\n",
       " 'knows',\n",
       " 'bodies',\n",
       " '##ks',\n",
       " 'someone',\n",
       " 'descriptive',\n",
       " '##und',\n",
       " 'ten',\n",
       " 'lectures',\n",
       " 'mastery',\n",
       " 'bestowed',\n",
       " 'potential',\n",
       " '1930',\n",
       " 'getting',\n",
       " 'described',\n",
       " '##vis',\n",
       " 'capt',\n",
       " 'knowledge',\n",
       " 'leaving',\n",
       " 'enlisted',\n",
       " 'playing',\n",
       " 'preferred',\n",
       " 'christian',\n",
       " 'working',\n",
       " 'aa',\n",
       " 'roots',\n",
       " '##ari',\n",
       " 'strongly',\n",
       " 'ode',\n",
       " '##del',\n",
       " 'rather',\n",
       " '##ion',\n",
       " 'fraternity',\n",
       " 'insist',\n",
       " '##ging',\n",
       " 'arise',\n",
       " 'ineffective',\n",
       " '343',\n",
       " 'attacked',\n",
       " 'refer',\n",
       " 'tightening',\n",
       " 'figure',\n",
       " 'adulthood',\n",
       " 'iii',\n",
       " 'pleasant',\n",
       " 'university',\n",
       " 'prove',\n",
       " 'li',\n",
       " 'must',\n",
       " 'carolina',\n",
       " 'cock',\n",
       " '##ize',\n",
       " 'international',\n",
       " 'depart',\n",
       " 'idea',\n",
       " 'welcome',\n",
       " '##tive',\n",
       " 'perhaps',\n",
       " 'handled',\n",
       " 'part',\n",
       " '##nish',\n",
       " 'regulated',\n",
       " 'lou',\n",
       " 'identified',\n",
       " 'back',\n",
       " 'compilations',\n",
       " 'openly',\n",
       " 'bases',\n",
       " 'restoring',\n",
       " '##tment',\n",
       " 'senate',\n",
       " 'stake',\n",
       " '##lo',\n",
       " 'mothers',\n",
       " 'govern',\n",
       " 'mode',\n",
       " 'goods',\n",
       " 'interest',\n",
       " 'records',\n",
       " 'voyage',\n",
       " 'charlie',\n",
       " 'edition',\n",
       " 'disc',\n",
       " 'employers',\n",
       " 'watched',\n",
       " 'give',\n",
       " 'larger',\n",
       " '000',\n",
       " '##v',\n",
       " 'log',\n",
       " 'pleased',\n",
       " '##tro',\n",
       " 'tires',\n",
       " 'offer',\n",
       " 'efficiency',\n",
       " 'relationships',\n",
       " 'instruction',\n",
       " '55',\n",
       " 'experts',\n",
       " 'satisfaction',\n",
       " 'afterwards',\n",
       " 'aid',\n",
       " 'scattered',\n",
       " '##y',\n",
       " 'supervision',\n",
       " 'fathers',\n",
       " 'because',\n",
       " 'divisions',\n",
       " 'netherlands',\n",
       " 'national',\n",
       " 'blame',\n",
       " 'lion',\n",
       " 'burning',\n",
       " 'register',\n",
       " 'recently',\n",
       " 'otherwise',\n",
       " 'agriculture',\n",
       " 'realization',\n",
       " '##use',\n",
       " 'concerning',\n",
       " '##nts',\n",
       " 'constant',\n",
       " 'childhood',\n",
       " 'printers',\n",
       " 'seventeen',\n",
       " 'oath',\n",
       " '##ction',\n",
       " 'junior',\n",
       " 'actual',\n",
       " 'according',\n",
       " 'appeal',\n",
       " 'ep',\n",
       " 'bought',\n",
       " 'the',\n",
       " 'foot',\n",
       " 'tools',\n",
       " 'choosing',\n",
       " 'baldwin',\n",
       " '##raf',\n",
       " 'temper',\n",
       " 'regulate',\n",
       " 'apologized',\n",
       " 'drop',\n",
       " 'eldest',\n",
       " 'minimum',\n",
       " 'behind',\n",
       " 'unpublished',\n",
       " 'unit',\n",
       " 'affair',\n",
       " 'sensitive',\n",
       " 'raised',\n",
       " 'remedy',\n",
       " '##tting',\n",
       " '##hend',\n",
       " 'family',\n",
       " 'complete',\n",
       " 'pawn',\n",
       " 'pass',\n",
       " 'value',\n",
       " 'fright',\n",
       " 'genetic',\n",
       " 'appears',\n",
       " 'harmony',\n",
       " 'asks',\n",
       " 'personal',\n",
       " 'voice',\n",
       " '1881',\n",
       " 'emphasizes',\n",
       " 'county',\n",
       " 'push',\n",
       " 'cell',\n",
       " 'sisters',\n",
       " '61',\n",
       " 'fault',\n",
       " 'parade',\n",
       " 'importance',\n",
       " 'tackle',\n",
       " '1913',\n",
       " 'soc',\n",
       " 'gives',\n",
       " 'specialist',\n",
       " '##5',\n",
       " 'function',\n",
       " 'und',\n",
       " 'dream',\n",
       " 'able',\n",
       " 'wilmington',\n",
       " 'life',\n",
       " 'fighting',\n",
       " 'familiar',\n",
       " 'syllables',\n",
       " 'om',\n",
       " 'compensation',\n",
       " 'enjoyed',\n",
       " 'judgment',\n",
       " 'proper',\n",
       " '##ff',\n",
       " 'work',\n",
       " 'hydroelectric',\n",
       " 'poverty',\n",
       " '##osh',\n",
       " 'glad',\n",
       " 'stores',\n",
       " 'hi',\n",
       " 'radio',\n",
       " '##ricted',\n",
       " 'possibility',\n",
       " 'stream',\n",
       " '##ul',\n",
       " 'regain',\n",
       " 'faced',\n",
       " '##ractive',\n",
       " 'vera',\n",
       " 'school',\n",
       " 'des',\n",
       " '##ly',\n",
       " 'breathe',\n",
       " 'evident',\n",
       " 'opposite',\n",
       " 'exhaust',\n",
       " '##fell',\n",
       " 'presentation',\n",
       " 'serves',\n",
       " 'adolescents',\n",
       " 'apparent',\n",
       " 'airlines',\n",
       " 'exposition',\n",
       " '##ts',\n",
       " 'different',\n",
       " '##0',\n",
       " 'communication',\n",
       " 'emphasize',\n",
       " 'neighbor',\n",
       " 'copy',\n",
       " 'copies',\n",
       " '##vian',\n",
       " 'utilized',\n",
       " 'theater',\n",
       " 'expects',\n",
       " 'rows',\n",
       " 'slammed',\n",
       " 'vice',\n",
       " 'looking',\n",
       " '##manship',\n",
       " 'improvement',\n",
       " '##r',\n",
       " 'denmark',\n",
       " 'ton',\n",
       " 'waist',\n",
       " 'organ',\n",
       " '18',\n",
       " 'mostly',\n",
       " 'whom',\n",
       " 'bad',\n",
       " 'yesterday',\n",
       " 'fleet',\n",
       " 'always',\n",
       " 'see',\n",
       " 'variations',\n",
       " 'us',\n",
       " '##city',\n",
       " 'modern',\n",
       " '##86',\n",
       " 'above',\n",
       " 'understood',\n",
       " 'associations',\n",
       " '##ani',\n",
       " 'february',\n",
       " 'your',\n",
       " '##fi',\n",
       " 'sterling',\n",
       " '225',\n",
       " 'obvious',\n",
       " 'poems',\n",
       " '##in',\n",
       " 'consumed',\n",
       " 'generations',\n",
       " 'researchers',\n",
       " 'relation',\n",
       " 'canada',\n",
       " 'nurses',\n",
       " 'straight',\n",
       " 'oil',\n",
       " '##s',\n",
       " 'founding',\n",
       " '##ous',\n",
       " 'bulk',\n",
       " 'changing',\n",
       " 'relatives',\n",
       " 'israel',\n",
       " 'incomplete',\n",
       " 'represent',\n",
       " 'near',\n",
       " 'totally',\n",
       " 'were',\n",
       " '##pp',\n",
       " 'acquired',\n",
       " 'distress',\n",
       " 'first',\n",
       " 'is',\n",
       " 'gal',\n",
       " '7',\n",
       " 'influenced',\n",
       " '##formed',\n",
       " 'selling',\n",
       " 'than',\n",
       " 'form',\n",
       " 'aim',\n",
       " 'informally',\n",
       " 'similar',\n",
       " '##ran',\n",
       " 'we',\n",
       " 'scandinavia',\n",
       " 'turn',\n",
       " 'samples',\n",
       " 'dress',\n",
       " 'sp',\n",
       " 'desire',\n",
       " 'communicate',\n",
       " 'have',\n",
       " 'selections',\n",
       " 'settings',\n",
       " '153',\n",
       " 'instances',\n",
       " 'someday',\n",
       " '##al',\n",
       " 'people',\n",
       " 'would',\n",
       " 'man',\n",
       " 'came',\n",
       " 'courtship',\n",
       " 'looked',\n",
       " 'from',\n",
       " '##ride',\n",
       " 'carlisle',\n",
       " 'things',\n",
       " 'season',\n",
       " '##vance',\n",
       " 'continues',\n",
       " 'abrupt',\n",
       " 'achieved',\n",
       " 'economic',\n",
       " 'neighboring',\n",
       " 'heard',\n",
       " 'produce',\n",
       " 'specialists',\n",
       " 'among',\n",
       " 'restored',\n",
       " '##essed',\n",
       " 'guided',\n",
       " 'wedding',\n",
       " 'him',\n",
       " 'research',\n",
       " 'ground',\n",
       " 'make',\n",
       " 'comprehension',\n",
       " 'barley',\n",
       " 'pottery',\n",
       " 'ni',\n",
       " 'profitable',\n",
       " 'simply',\n",
       " 'til',\n",
       " 'trees',\n",
       " 'food',\n",
       " 'loves',\n",
       " 'million',\n",
       " 'folks',\n",
       " 'fifteen',\n",
       " 'departure',\n",
       " 'excellent',\n",
       " 'status',\n",
       " '##red',\n",
       " 'flour',\n",
       " 'available',\n",
       " 'joint',\n",
       " 'guidance',\n",
       " 'donald',\n",
       " 'generally',\n",
       " '64',\n",
       " 'session',\n",
       " 'remarkable',\n",
       " 'application',\n",
       " 'bo',\n",
       " 'audio',\n",
       " 'heritage',\n",
       " 'response',\n",
       " 'equivalent',\n",
       " 'assistance',\n",
       " '13',\n",
       " 'could',\n",
       " 'elected',\n",
       " '##well',\n",
       " 'trieste',\n",
       " 'focused',\n",
       " 'worse',\n",
       " ':',\n",
       " 'mind',\n",
       " '107',\n",
       " 'gene',\n",
       " 'interpret',\n",
       " 'holidays',\n",
       " 'resonance',\n",
       " 'talks',\n",
       " 'connection',\n",
       " 'columbus',\n",
       " 'sentence',\n",
       " '##ting',\n",
       " 'maintains',\n",
       " 'fell',\n",
       " 'applied',\n",
       " 'provision',\n",
       " 'utilizing',\n",
       " 'minded',\n",
       " 'entry',\n",
       " 'conditional',\n",
       " 'wherever',\n",
       " '?',\n",
       " '##pet',\n",
       " 'involved',\n",
       " 'rein',\n",
       " 'engages',\n",
       " 'cards',\n",
       " 'witness',\n",
       " 'front',\n",
       " '##em',\n",
       " 'ab',\n",
       " '##les',\n",
       " 'expression',\n",
       " 'reduce',\n",
       " 'government',\n",
       " 'concerns',\n",
       " 'liberal',\n",
       " 'raw',\n",
       " 'valuable',\n",
       " 'distribution',\n",
       " 'exhibits',\n",
       " 'several',\n",
       " 'photograph',\n",
       " 'jobs',\n",
       " 'authorized',\n",
       " 'listener',\n",
       " 'introduced',\n",
       " '375',\n",
       " 'hear',\n",
       " 'productive',\n",
       " '9th',\n",
       " 'foster',\n",
       " 'winter',\n",
       " 'race',\n",
       " 'operatives',\n",
       " 'regulations',\n",
       " 'carpets',\n",
       " 'thrilled',\n",
       " 'responsibility',\n",
       " 'bird',\n",
       " 'consultant',\n",
       " '##co',\n",
       " 'pleaded',\n",
       " 'keynote',\n",
       " 'k',\n",
       " 'sway',\n",
       " 'phil',\n",
       " ...}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similars = set(list_timestamps[0]['token'])\n",
    "for i in range(1, len(list_timestamps)):\n",
    "    similars = set(check_similars(list_timestamps[0], list_timestamps[i]))\n",
    "similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "05e81713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists!\n"
     ]
    }
   ],
   "source": [
    "if \"theory\" in similars:\n",
    "    print('exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2cfa40fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       token         0         1        2         3         4         5  \\\n",
      "4223  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
      "\n",
      "             6         7        8  ...       758       759       760  \\\n",
      "4223 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714   \n",
      "\n",
      "           761       762       763       764       765       766       767  \n",
      "4223 -0.293807 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
      "\n",
      "[1 rows x 769 columns]\n",
      "       token         0         1        2         3         4         5  \\\n",
      "4223  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
      "\n",
      "             6         7        8  ...       758       759       760  \\\n",
      "4223 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714   \n",
      "\n",
      "           761       762       763       764       765       766       767  \n",
      "4223 -0.293807 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
      "\n",
      "[1 rows x 769 columns]\n",
      "       token         0         1        2         3         4         5  \\\n",
      "4223  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
      "\n",
      "             6         7        8  ...       758       759       760  \\\n",
      "4223 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714   \n",
      "\n",
      "           761       762       763       764       765       766       767  \n",
      "4223 -0.293807 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
      "\n",
      "[1 rows x 769 columns]\n",
      "       token         0         1        2         3         4         5  \\\n",
      "4223  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
      "\n",
      "             6         7        8  ...       758       759       760  \\\n",
      "4223 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714   \n",
      "\n",
      "           761       762       763       764       765       766       767  \n",
      "4223 -0.293807 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
      "\n",
      "[1 rows x 769 columns]\n",
      "       token         0         1        2         3         4         5  \\\n",
      "4223  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
      "\n",
      "             6         7        8  ...       758       759       760  \\\n",
      "4223 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714   \n",
      "\n",
      "           761       762       763       764       765       766       767  \n",
      "4223 -0.293807 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
      "\n",
      "[1 rows x 769 columns]\n",
      "       token         0         1        2         3         4         5  \\\n",
      "4223  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
      "\n",
      "             6         7        8  ...       758       759       760  \\\n",
      "4223 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714   \n",
      "\n",
      "           761       762       763       764       765       766       767  \n",
      "4223 -0.293807 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
      "\n",
      "[1 rows x 769 columns]\n",
      "       token         0         1        2         3         4         5  \\\n",
      "4223  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
      "\n",
      "             6         7        8  ...       758       759       760  \\\n",
      "4223 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714   \n",
      "\n",
      "           761       762       763       764       765       766       767  \n",
      "4223 -0.293807 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
      "\n",
      "[1 rows x 769 columns]\n",
      "       token         0         1        2         3         4         5  \\\n",
      "4223  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
      "\n",
      "             6         7        8  ...       758       759       760  \\\n",
      "4223 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714   \n",
      "\n",
      "           761       762       763       764       765       766       767  \n",
      "4223 -0.293807 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
      "\n",
      "[1 rows x 769 columns]\n",
      "       token         0         1        2         3         4         5  \\\n",
      "4223  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
      "\n",
      "             6         7        8  ...       758       759       760  \\\n",
      "4223 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714   \n",
      "\n",
      "           761       762       763       764       765       766       767  \n",
      "4223 -0.293807 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
      "\n",
      "[1 rows x 769 columns]\n",
      "       token         0         1        2         3         4         5  \\\n",
      "4223  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
      "\n",
      "             6         7        8  ...       758       759       760  \\\n",
      "4223 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714   \n",
      "\n",
      "           761       762       763       764       765       766       767  \n",
      "4223 -0.293807 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
      "\n",
      "[1 rows x 769 columns]\n"
     ]
    }
   ],
   "source": [
    "df_theory = pd.DataFrame()\n",
    "for i in range(1, len(list_timestamps)):\n",
    "    df = list_timestamps[i].loc[list_timestamps[i]['token']== \"theory\"]\n",
    "    print(df)\n",
    "    df_theory = pd.concat([df_theory, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "13f12f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>theory</td>\n",
       "      <td>-0.184632</td>\n",
       "      <td>0.550466</td>\n",
       "      <td>-0.03259</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.219331</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>0.168834</td>\n",
       "      <td>0.04756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094542</td>\n",
       "      <td>0.289876</td>\n",
       "      <td>0.199714</td>\n",
       "      <td>-0.293807</td>\n",
       "      <td>-0.380943</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.251617</td>\n",
       "      <td>-0.311346</td>\n",
       "      <td>-0.150466</td>\n",
       "      <td>0.324085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>theory</td>\n",
       "      <td>-0.184632</td>\n",
       "      <td>0.550466</td>\n",
       "      <td>-0.03259</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.219331</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>0.168834</td>\n",
       "      <td>0.04756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094542</td>\n",
       "      <td>0.289876</td>\n",
       "      <td>0.199714</td>\n",
       "      <td>-0.293807</td>\n",
       "      <td>-0.380943</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.251617</td>\n",
       "      <td>-0.311346</td>\n",
       "      <td>-0.150466</td>\n",
       "      <td>0.324085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>theory</td>\n",
       "      <td>-0.184632</td>\n",
       "      <td>0.550466</td>\n",
       "      <td>-0.03259</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.219331</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>0.168834</td>\n",
       "      <td>0.04756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094542</td>\n",
       "      <td>0.289876</td>\n",
       "      <td>0.199714</td>\n",
       "      <td>-0.293807</td>\n",
       "      <td>-0.380943</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.251617</td>\n",
       "      <td>-0.311346</td>\n",
       "      <td>-0.150466</td>\n",
       "      <td>0.324085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>theory</td>\n",
       "      <td>-0.184632</td>\n",
       "      <td>0.550466</td>\n",
       "      <td>-0.03259</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.219331</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>0.168834</td>\n",
       "      <td>0.04756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094542</td>\n",
       "      <td>0.289876</td>\n",
       "      <td>0.199714</td>\n",
       "      <td>-0.293807</td>\n",
       "      <td>-0.380943</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.251617</td>\n",
       "      <td>-0.311346</td>\n",
       "      <td>-0.150466</td>\n",
       "      <td>0.324085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theory</td>\n",
       "      <td>-0.184632</td>\n",
       "      <td>0.550466</td>\n",
       "      <td>-0.03259</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.219331</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>0.168834</td>\n",
       "      <td>0.04756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094542</td>\n",
       "      <td>0.289876</td>\n",
       "      <td>0.199714</td>\n",
       "      <td>-0.293807</td>\n",
       "      <td>-0.380943</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.251617</td>\n",
       "      <td>-0.311346</td>\n",
       "      <td>-0.150466</td>\n",
       "      <td>0.324085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>theory</td>\n",
       "      <td>-0.184632</td>\n",
       "      <td>0.550466</td>\n",
       "      <td>-0.03259</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.219331</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>0.168834</td>\n",
       "      <td>0.04756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094542</td>\n",
       "      <td>0.289876</td>\n",
       "      <td>0.199714</td>\n",
       "      <td>-0.293807</td>\n",
       "      <td>-0.380943</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.251617</td>\n",
       "      <td>-0.311346</td>\n",
       "      <td>-0.150466</td>\n",
       "      <td>0.324085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>theory</td>\n",
       "      <td>-0.184632</td>\n",
       "      <td>0.550466</td>\n",
       "      <td>-0.03259</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.219331</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>0.168834</td>\n",
       "      <td>0.04756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094542</td>\n",
       "      <td>0.289876</td>\n",
       "      <td>0.199714</td>\n",
       "      <td>-0.293807</td>\n",
       "      <td>-0.380943</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.251617</td>\n",
       "      <td>-0.311346</td>\n",
       "      <td>-0.150466</td>\n",
       "      <td>0.324085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>theory</td>\n",
       "      <td>-0.184632</td>\n",
       "      <td>0.550466</td>\n",
       "      <td>-0.03259</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.219331</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>0.168834</td>\n",
       "      <td>0.04756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094542</td>\n",
       "      <td>0.289876</td>\n",
       "      <td>0.199714</td>\n",
       "      <td>-0.293807</td>\n",
       "      <td>-0.380943</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.251617</td>\n",
       "      <td>-0.311346</td>\n",
       "      <td>-0.150466</td>\n",
       "      <td>0.324085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>theory</td>\n",
       "      <td>-0.184632</td>\n",
       "      <td>0.550466</td>\n",
       "      <td>-0.03259</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.219331</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>0.168834</td>\n",
       "      <td>0.04756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094542</td>\n",
       "      <td>0.289876</td>\n",
       "      <td>0.199714</td>\n",
       "      <td>-0.293807</td>\n",
       "      <td>-0.380943</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.251617</td>\n",
       "      <td>-0.311346</td>\n",
       "      <td>-0.150466</td>\n",
       "      <td>0.324085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>theory</td>\n",
       "      <td>-0.184632</td>\n",
       "      <td>0.550466</td>\n",
       "      <td>-0.03259</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.219331</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>0.168834</td>\n",
       "      <td>0.04756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094542</td>\n",
       "      <td>0.289876</td>\n",
       "      <td>0.199714</td>\n",
       "      <td>-0.293807</td>\n",
       "      <td>-0.380943</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.251617</td>\n",
       "      <td>-0.311346</td>\n",
       "      <td>-0.150466</td>\n",
       "      <td>0.324085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    token         0         1        2         3         4         5  \\\n",
       "0  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
       "1  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
       "2  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
       "3  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
       "4  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
       "5  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
       "6  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
       "7  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
       "8  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
       "9  theory -0.184632  0.550466 -0.03259  0.037268  0.219331  0.159226   \n",
       "\n",
       "          6         7        8  ...       758       759       760       761  \\\n",
       "0 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714 -0.293807   \n",
       "1 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714 -0.293807   \n",
       "2 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714 -0.293807   \n",
       "3 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714 -0.293807   \n",
       "4 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714 -0.293807   \n",
       "5 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714 -0.293807   \n",
       "6 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714 -0.293807   \n",
       "7 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714 -0.293807   \n",
       "8 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714 -0.293807   \n",
       "9 -0.048129  0.168834  0.04756  ... -0.094542  0.289876  0.199714 -0.293807   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
       "1 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
       "2 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
       "3 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
       "4 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
       "5 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
       "6 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
       "7 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
       "8 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
       "9 -0.380943 -0.121988 -0.251617 -0.311346 -0.150466  0.324085  \n",
       "\n",
       "[10 rows x 769 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "75d95b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances_single_df(df1):\n",
    "    distances = []\n",
    "    emb1 = torch.tensor(df1.iloc[0, 1:].astype(float).values.flatten(), dtype=torch.float)\n",
    "    for index, row in df1.iterrows():\n",
    "        print(f\"Processing row {index+1}{row['token']}\")\n",
    "        emb2 = torch.tensor(row[1:].astype(float).values.flatten(), dtype=torch.float)\n",
    "\n",
    "        cos_sim = F.cosine_similarity(emb1, emb2, dim=0)\n",
    "        distances.append((row['token'], cos_sim.item()))\n",
    "    return pd.DataFrame(distances, columns=['token', 'distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dc488d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 1theory\n",
      "Processing row 2theory\n",
      "Processing row 3theory\n",
      "Processing row 4theory\n",
      "Processing row 5theory\n",
      "Processing row 6theory\n",
      "Processing row 7theory\n",
      "Processing row 8theory\n",
      "Processing row 9theory\n",
      "Processing row 10theory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>theory</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>theory</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>theory</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>theory</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theory</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>theory</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>theory</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>theory</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>theory</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>theory</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token  distance\n",
       "0  theory       1.0\n",
       "1  theory       1.0\n",
       "2  theory       1.0\n",
       "3  theory       1.0\n",
       "4  theory       1.0\n",
       "5  theory       1.0\n",
       "6  theory       1.0\n",
       "7  theory       1.0\n",
       "8  theory       1.0\n",
       "9  theory       1.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theory_distances = compute_distances_single_df(df_theory)\n",
    "theory_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0eafd119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>professor</td>\n",
       "      <td>-0.661329</td>\n",
       "      <td>0.179339</td>\n",
       "      <td>0.095199</td>\n",
       "      <td>0.071153</td>\n",
       "      <td>0.200849</td>\n",
       "      <td>0.378426</td>\n",
       "      <td>0.069264</td>\n",
       "      <td>0.597784</td>\n",
       "      <td>0.361809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3748</td>\n",
       "      <td>-0.232973</td>\n",
       "      <td>0.526307</td>\n",
       "      <td>-0.197581</td>\n",
       "      <td>-0.43336</td>\n",
       "      <td>-0.263111</td>\n",
       "      <td>-0.559455</td>\n",
       "      <td>0.127518</td>\n",
       "      <td>0.132996</td>\n",
       "      <td>0.23483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          token         0         1         2         3         4         5  \\\n",
       "3413  professor -0.661329  0.179339  0.095199  0.071153  0.200849  0.378426   \n",
       "\n",
       "             6         7         8  ...     758       759       760       761  \\\n",
       "3413  0.069264  0.597784  0.361809  ... -0.3748 -0.232973  0.526307 -0.197581   \n",
       "\n",
       "          762       763       764       765       766      767  \n",
       "3413 -0.43336 -0.263111 -0.559455  0.127518  0.132996  0.23483  \n",
       "\n",
       "[1 rows x 769 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_1950 = df_avg_1950.loc[df_avg_1950['token']== \"professor\"]\n",
    "token_1951 = df_avg_1950.loc[df_avg_1950['token']== \"professor\"]\n",
    "token_1951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6b2c3a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_1950_embeddings = torch.tensor(token_1950.iloc[:, 1:].values, dtype=torch.float)\n",
    "df_avg_1951_embeddings = torch.tensor(token_1951.iloc[:, 1:].values, dtype=torch.float)\n",
    "df_avg_1950_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2050f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = F.cosine_similarity(df_avg_1950_embeddings, df_avg_1951_embeddings, dim=1)\n",
    "cos_dist = 1 - cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f88d2061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78585db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist = compute_distances(df_avg_1950, df_avg_1951, similars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2f3926f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>tensor(0.9733)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>tensor(0.9700)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>tensor(0.9672)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modern</td>\n",
       "      <td>tensor(0.8724)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>family</td>\n",
       "      <td>tensor(0.9345)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>better</td>\n",
       "      <td>tensor(0.9468)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>or</td>\n",
       "      <td>tensor(0.9771)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>worse</td>\n",
       "      <td>tensor(0.8872)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>than</td>\n",
       "      <td>tensor(0.9833)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>old</td>\n",
       "      <td>tensor(0.9145)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>?</td>\n",
       "      <td>tensor(0.9618)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>changing</td>\n",
       "      <td>tensor(0.7868)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>by</td>\n",
       "      <td>tensor(0.9744)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>h</td>\n",
       "      <td>tensor(0.7728)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.</td>\n",
       "      <td>tensor(0.9903)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>##is</td>\n",
       "      <td>tensor(0.7907)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>professor</td>\n",
       "      <td>tensor(0.8180)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>of</td>\n",
       "      <td>tensor(0.9725)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>,</td>\n",
       "      <td>tensor(0.9857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>state</td>\n",
       "      <td>tensor(0.6916)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>college</td>\n",
       "      <td>tensor(0.9090)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>american</td>\n",
       "      <td>tensor(0.8810)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>was</td>\n",
       "      <td>tensor(0.9574)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>male</td>\n",
       "      <td>tensor(0.8848)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-</td>\n",
       "      <td>tensor(0.9354)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>duty</td>\n",
       "      <td>tensor(0.7885)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bound</td>\n",
       "      <td>tensor(0.7417)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>parent</td>\n",
       "      <td>tensor(0.8384)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ce</td>\n",
       "      <td>tensor(0.7966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>##n</td>\n",
       "      <td>tensor(0.7560)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>##ed</td>\n",
       "      <td>tensor(0.9484)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>and</td>\n",
       "      <td>tensor(0.9734)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fertile</td>\n",
       "      <td>tensor(0.8241)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>it</td>\n",
       "      <td>tensor(0.9514)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>made</td>\n",
       "      <td>tensor(0.9654)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>rigorous</td>\n",
       "      <td>tensor(0.7118)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>an</td>\n",
       "      <td>tensor(0.9752)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>un</td>\n",
       "      <td>tensor(0.9567)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>##rel</td>\n",
       "      <td>tensor(0.6730)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>work</td>\n",
       "      <td>tensor(0.8905)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>world</td>\n",
       "      <td>tensor(0.8796)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>where</td>\n",
       "      <td>tensor(0.9431)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>a</td>\n",
       "      <td>tensor(0.9713)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>man</td>\n",
       "      <td>tensor(0.9565)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>’</td>\n",
       "      <td>tensor(0.8499)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>s</td>\n",
       "      <td>tensor(0.9364)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>measured</td>\n",
       "      <td>tensor(0.8646)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>no</td>\n",
       "      <td>tensor(0.9720)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>less</td>\n",
       "      <td>tensor(0.9657)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>his</td>\n",
       "      <td>tensor(0.9577)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token        distance\n",
       "0       [CLS]  tensor(0.9733)\n",
       "1          is  tensor(0.9700)\n",
       "2         the  tensor(0.9672)\n",
       "3      modern  tensor(0.8724)\n",
       "4      family  tensor(0.9345)\n",
       "5      better  tensor(0.9468)\n",
       "6          or  tensor(0.9771)\n",
       "7       worse  tensor(0.8872)\n",
       "8        than  tensor(0.9833)\n",
       "9         old  tensor(0.9145)\n",
       "10          ?  tensor(0.9618)\n",
       "11   changing  tensor(0.7868)\n",
       "12         by  tensor(0.9744)\n",
       "13          h  tensor(0.7728)\n",
       "14          .  tensor(0.9903)\n",
       "15       ##is  tensor(0.7907)\n",
       "16  professor  tensor(0.8180)\n",
       "17         of  tensor(0.9725)\n",
       "18          ,  tensor(0.9857)\n",
       "19      state  tensor(0.6916)\n",
       "20    college  tensor(0.9090)\n",
       "21   american  tensor(0.8810)\n",
       "22        was  tensor(0.9574)\n",
       "23       male  tensor(0.8848)\n",
       "24          -  tensor(0.9354)\n",
       "25       duty  tensor(0.7885)\n",
       "26      bound  tensor(0.7417)\n",
       "27     parent  tensor(0.8384)\n",
       "28         ce  tensor(0.7966)\n",
       "29        ##n  tensor(0.7560)\n",
       "30       ##ed  tensor(0.9484)\n",
       "31        and  tensor(0.9734)\n",
       "32    fertile  tensor(0.8241)\n",
       "33         it  tensor(0.9514)\n",
       "34       made  tensor(0.9654)\n",
       "35   rigorous  tensor(0.7118)\n",
       "36         an  tensor(0.9752)\n",
       "37         un  tensor(0.9567)\n",
       "38      ##rel  tensor(0.6730)\n",
       "39       work  tensor(0.8905)\n",
       "40      world  tensor(0.8796)\n",
       "41      where  tensor(0.9431)\n",
       "42          a  tensor(0.9713)\n",
       "43        man  tensor(0.9565)\n",
       "44          ’  tensor(0.8499)\n",
       "45          s  tensor(0.9364)\n",
       "46   measured  tensor(0.8646)\n",
       "47         no  tensor(0.9720)\n",
       "48       less  tensor(0.9657)\n",
       "49        his  tensor(0.9577)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dist[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09cec198",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_df_sorted = df_dist.sort_values(by='distance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8501b6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>students</td>\n",
       "      <td>tensor(0.9491)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>then</td>\n",
       "      <td>tensor(0.9488)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>cent</td>\n",
       "      <td>tensor(0.9485)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>their</td>\n",
       "      <td>tensor(0.9485)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>##est</td>\n",
       "      <td>tensor(0.9485)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>##ed</td>\n",
       "      <td>tensor(0.9484)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>based</td>\n",
       "      <td>tensor(0.9484)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>adequate</td>\n",
       "      <td>tensor(0.9483)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>student</td>\n",
       "      <td>tensor(0.9481)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>itself</td>\n",
       "      <td>tensor(0.9481)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>home</td>\n",
       "      <td>tensor(0.9481)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>2</td>\n",
       "      <td>tensor(0.9477)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>##ira</td>\n",
       "      <td>tensor(0.9473)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>##vis</td>\n",
       "      <td>tensor(0.9472)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>reason</td>\n",
       "      <td>tensor(0.9469)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>better</td>\n",
       "      <td>tensor(0.9468)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>difficult</td>\n",
       "      <td>tensor(0.9463)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>last</td>\n",
       "      <td>tensor(0.9462)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>among</td>\n",
       "      <td>tensor(0.9462)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>regard</td>\n",
       "      <td>tensor(0.9461)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>nearly</td>\n",
       "      <td>tensor(0.9461)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>tends</td>\n",
       "      <td>tensor(0.9460)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>concerning</td>\n",
       "      <td>tensor(0.9459)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>found</td>\n",
       "      <td>tensor(0.9458)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>good</td>\n",
       "      <td>tensor(0.9458)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>should</td>\n",
       "      <td>tensor(0.9457)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>out</td>\n",
       "      <td>tensor(0.9452)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>done</td>\n",
       "      <td>tensor(0.9452)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>expected</td>\n",
       "      <td>tensor(0.9451)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>used</td>\n",
       "      <td>tensor(0.9451)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>other</td>\n",
       "      <td>tensor(0.9450)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>results</td>\n",
       "      <td>tensor(0.9449)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>perhaps</td>\n",
       "      <td>tensor(0.9448)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>war</td>\n",
       "      <td>tensor(0.9445)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>purpose</td>\n",
       "      <td>tensor(0.9445)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>discusses</td>\n",
       "      <td>tensor(0.9443)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>does</td>\n",
       "      <td>tensor(0.9440)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>need</td>\n",
       "      <td>tensor(0.9439)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>limited</td>\n",
       "      <td>tensor(0.9437)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>being</td>\n",
       "      <td>tensor(0.9435)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>always</td>\n",
       "      <td>tensor(0.9435)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1949</td>\n",
       "      <td>tensor(0.9433)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>himself</td>\n",
       "      <td>tensor(0.9432)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>where</td>\n",
       "      <td>tensor(0.9431)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>either</td>\n",
       "      <td>tensor(0.9430)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>tensor(0.9430)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>cannot</td>\n",
       "      <td>tensor(0.9429)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>information</td>\n",
       "      <td>tensor(0.9428)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>same</td>\n",
       "      <td>tensor(0.9428)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>reader</td>\n",
       "      <td>tensor(0.9426)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token        distance\n",
       "502      students  tensor(0.9491)\n",
       "910          then  tensor(0.9488)\n",
       "1454         cent  tensor(0.9485)\n",
       "185         their  tensor(0.9485)\n",
       "314         ##est  tensor(0.9485)\n",
       "30           ##ed  tensor(0.9484)\n",
       "815         based  tensor(0.9484)\n",
       "816      adequate  tensor(0.9483)\n",
       "807       student  tensor(0.9481)\n",
       "445        itself  tensor(0.9481)\n",
       "237          home  tensor(0.9481)\n",
       "690             2  tensor(0.9477)\n",
       "1612        ##ira  tensor(0.9473)\n",
       "906         ##vis  tensor(0.9472)\n",
       "503        reason  tensor(0.9469)\n",
       "5          better  tensor(0.9468)\n",
       "505     difficult  tensor(0.9463)\n",
       "1458         last  tensor(0.9462)\n",
       "1072        among  tensor(0.9462)\n",
       "381        regard  tensor(0.9461)\n",
       "470        nearly  tensor(0.9461)\n",
       "528         tends  tensor(0.9460)\n",
       "757    concerning  tensor(0.9459)\n",
       "268         found  tensor(0.9458)\n",
       "154          good  tensor(0.9458)\n",
       "685        should  tensor(0.9457)\n",
       "353           out  tensor(0.9452)\n",
       "1198         done  tensor(0.9452)\n",
       "138      expected  tensor(0.9451)\n",
       "596          used  tensor(0.9451)\n",
       "128         other  tensor(0.9450)\n",
       "571       results  tensor(0.9449)\n",
       "841       perhaps  tensor(0.9448)\n",
       "278           war  tensor(0.9445)\n",
       "580       purpose  tensor(0.9445)\n",
       "1163    discusses  tensor(0.9443)\n",
       "377          does  tensor(0.9440)\n",
       "766          need  tensor(0.9439)\n",
       "1043      limited  tensor(0.9437)\n",
       "235         being  tensor(0.9435)\n",
       "828        always  tensor(0.9435)\n",
       "1215         1949  tensor(0.9433)\n",
       "383       himself  tensor(0.9432)\n",
       "41          where  tensor(0.9431)\n",
       "1391       either  tensor(0.9430)\n",
       "187         [SEP]  tensor(0.9430)\n",
       "401        cannot  tensor(0.9429)\n",
       "782   information  tensor(0.9428)\n",
       "496          same  tensor(0.9428)\n",
       "728        reader  tensor(0.9426)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_df_sorted[150:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c23a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cefc8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "list =  [\"professor\", \"university\", \"discussion\", \"knowledge\", \"student\", \"information\"]\n",
    "distance_df_plot = distance_df_sorted[distance_df_sorted['token'].isin(list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72694fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(distance_df_plot['token'], distance_df_plot['distance'], color='tomato')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.title(\"Top 10 Tokens by Semantic Drift\")\n",
    "plt.gca().invert_yaxis()  # Most drifted token on top\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4025ceaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Select target tokens\n",
    "list =  [\"professor\", \"university\", \"discussion\", \"knowledge\", \"student\", \"information\"]\n",
    "\n",
    "# Step 2: Extract embeddings from both DataFrames\n",
    "embeddings_1950 = df_avg_1950[df_avg_1950['token'].isin(list)]\n",
    "embeddings_1951 = df_avg_1951[df_avg_1951['token'].isin(list)]\n",
    "\n",
    "\n",
    "# Step 3: Stack and reduce dimensionality\n",
    "all_embeddings = pd.concat([embeddings_1950, embeddings_1951])\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(all_embeddings.iloc[:, 1:].values)\n",
    "\n",
    "# Step 4: Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, token in enumerate(list):\n",
    "    x1, y1 = reduced[i]      # 1950\n",
    "    x2, y2 = reduced[i + len(list)]  # 1951\n",
    "    plt.scatter(x1, y1, color='red', label='1950' if i == 0 else \"\")\n",
    "    plt.scatter(x2, y2, color='blue', label='1951' if i == 0 else \"\")\n",
    "    plt.plot([x1, x2], [y1, y2], 'gray', linestyle='--', linewidth=1)\n",
    "    plt.text(x1, y1, f\"{token}_50\", fontsize=9, ha='right')\n",
    "    plt.text(x2, y2, f\"{token}_20\", fontsize=9, ha='left')\n",
    "\n",
    "plt.title(\"Semantic Drift of Tokens from 1950 to 1951\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b0347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada_dho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
